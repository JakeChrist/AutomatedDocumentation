<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul>
        <li><a href="cache.html">cache</a></li>
<li><a href="chunk_utils.html">chunk_utils</a></li>
<li><a href="docgenerator.html">docgenerator</a></li>
<li><a href="explaincode.html">explaincode</a></li>
<li><a href="gui_wrapper.html">gui_wrapper</a></li>
<li><a href="html_writer.html">html_writer</a></li>
<li><a href="llm_client.html">llm_client</a></li>
<li><a href="manual_utils.html">manual_utils</a></li>
<li><a href="parser_matlab.html">parser_matlab</a></li>
<li><a href="parser_python.html">parser_python</a></li>
<li><a href="reviewer.html">reviewer</a></li>
<li><a href="scanner.html">scanner</a></li>
<li><a href="setup.html">setup</a></li>
<li><a href="summarize_utils.html">summarize_utils</a></li>
<li><a href="test_cache.html">test_cache</a></li>
<li><a href="test_chunk_utils.html">test_chunk_utils</a></li>
<li><a href="test_docgenerator.html">test_docgenerator</a></li>
<li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li>
<li><a href="test_explaincode.html">test_explaincode</a></li>
<li><a href="test_html_writer.html">test_html_writer</a></li>
<li><a href="test_integration.html">test_integration</a></li>
<li><a href="test_llm_client.html">test_llm_client</a></li>
<li><a href="test_manual_utils.html">test_manual_utils</a></li>
<li><a href="test_parser_matlab.html">test_parser_matlab</a></li>
<li><a href="test_parser_python.html">test_parser_python</a></li>
<li><a href="test_reviewer.html">test_reviewer</a></li>
<li><a href="test_scanner.html">test_scanner</a></li>
        </ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM generates static HTML documentation for Python and MATLAB projects by analyzing source files with a local LLM. It supports nested functions and subclasses, rendering complex structures as expandable sections in the output. The tool includes both command-line and graphical user interface options for project documentation generation and provides utilities like `explaincode.py` for generating lightweight project summaries with optional code analysis.
This project appears to be a comprehensive tool for generating and managing documentation. It includes modules for caching responses, chunking text, summarizing code, interacting with language models, parsing different programming languages, reviewing generated documentation, scanning directories, and writing HTML output. The system seems designed to handle various aspects of documentation generation, from initial parsing and summarization to final rendering and review.</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>A simple on-disk cache for storing and retrieving LLM (Large Language Model) responses. It uses a JSON file to persist mappings from stable keys to LLM responses. The `ResponseCache` class provides methods to get and set values in the cache, as well as a static method to generate deterministic keys based on file paths and content.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>This module provides utility functions for text processing, specifically focusing on tokenization and text chunking. It includes:

1. `get_tokenizer()`: Returns a tokenizer object used for estimating token counts. If the `tiktoken` library is available, it uses it; otherwise, it falls back to a simple character-based tokenizer.

2. `_split_blocks(text: str) -&gt; List[str]`: Splits Markdown text into paragraphs, headings, and fenced code blocks based on natural boundaries such as blank lines, Markdown headings, or fenced code blocks.

3. `_split_long_block(block: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: A fallback splitter that uses a character-based approximation to split long blocks of text that exceed the desired token size.

4. `chunk_text(text: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: Splits the input text into chunks roughly `chunk_size_tokens` each while respecting natural break points like blank lines, Markdown headings, and fenced code blocks. If a single block exceeds the token limit, it falls back to splitting by approximate character length.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>This module provides a command-line interface for generating HTML documentation using DocGen-LM. It scans a source tree for Python and MATLAB files, parses them, requests summaries from a running LLM, and writes the documentation to an output directory. The module includes functions for cleaning the output directory, summarizing text using an LLM client with caching, chunking modules by structure, summarizing module chunks, building function prompts, rewriting docstrings, recursively summarizing methods of classes and subclasses, and summarizing classes. It utilizes an LLM client (`LLMClient`), a response cache (`ResponseCache`), various prompts, and tokenization through a tokenizer object. The script supports parsing and summarizing Python and MATLAB files, ignoring specified paths, and customizing the LLM&#x27;s base URL and model settings. It also handles reading README and Markdown files for additional context in the documentation.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>This module defines a comprehensive project summary generator from existing documentation and sample files. It includes classes and functions for parsing configuration, collecting relevant files, slugifying text, inserting navigation entries into an index file, extracting plain text from various file types, detecting placeholders, mapping evidence to sections, ranking code files based on heuristics, and more. The module also defines functions to extract relevant code snippets from files, collect these snippets based on sections, and generate a manual using an LLM client. It includes utilities for rendering HTML, parsing text into structured sections, validating references, inferring missing sections, and writing the rendered output as a PDF. Additionally, it provides a `main` function that sets up argument parsing for summarizing project documentation, processes command-line arguments to configure parameters, collects documentation files, extracts text, initializes an LLM client, and generates a manual, handling placeholders and rendering the final output in specified formats.</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>This code defines a PyQt5 application for running documentation and explanation generation tools. It includes:

- A `PathLineEdit` class for file path input with drag-and-drop functionality.
- A `CollapsibleBox` class for creating collapsible sections in the UI.
- A `CommandRunner` class that runs shell commands asynchronously, emitting output and completion signals.
- A `MainWindow` class that sets up the GUI, handles user interactions, and manages running commands.

The main window includes:
- Fields for selecting project and output directories.
- Options for DocGen and ExplainCode tools, including language selection and data inclusion.
- A log area to display command output.
- Buttons to run DocGen, ExplainCode, or both.</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>This module provides utilities for rendering documentation pages using simple template substitution. It includes functions to highlight code snippets and render HTML content based on project summaries and module data. The module supports Python and MATLAB languages. It can generate `index.html` and individual module documentation pages, complete with navigation links and highlighted source code.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>This module provides an interface to communicate with a local language model server (LMStudio) using its HTTP API. It includes:

- A `SYSTEM_PROMPT` and `_COMMON_RULES` for defining guidelines for documentation generation.
- A `README_PROMPT` for summarizing README files.
- A dictionary `PROMPT_TEMPLATES` containing different prompt templates for summarizing modules, classes, functions, READMEs, projects, docstrings, and user manuals.
- A `sanitize_summary` function to clean up generated summaries by removing unwanted phrases.
- An `LLMClient` class that:
- Initializes with a base URL and model name.
- Includes a `ping` method to check if the LMStudio server is reachable.
- Implements a `summarize` method to send text and prompt type to the LMStudio API, retrying up to three times on failure.</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>This module provides functions for splitting text into chunks and generating summaries using a language model. It includes:

- `_count_tokens`: Counts the number of tokens in a given text.
- `_split_text`: Splits a text into chunks based on token and character limits.
- `chunk_docs`: Splits multiple documents into roughly equal-sized chunks.
- `find_placeholders`: Finds placeholder tokens in a text.
- `_summarize_manual`: Generates a manual summary for a given text using a specified chunking strategy. It handles both automatic and manual chunking, caching responses to avoid redundant requests.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>This module provides a function `parse_matlab_file` that parses MATLAB `.m` files and extracts basic structure. It reads the file content, identifies leading comment lines as the file header, and uses regular expressions to find and extract function declarations along with their arguments. The result is returned as a dictionary containing the file header comments and a list of functions, each represented by its name and arguments.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>This module provides a parser for Python files using the `ast` module. It extracts structured information according to the Software Requirements Specification (SRS). The parser can handle classes and functions, including their signatures, docstrings, returns types, and nested definitions. It also supports asynchronous functions and methods. The main function, `parse_python_file`, reads a Python source file and returns a dictionary containing the module&#x27;s docstring, classes, and functions.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>This module provides a tool for reviewing HTML documentation generated by DocGen-LM. It includes functions to check for assistant-like phrases, contradictions, and hallucinations in the HTML content. The `review_directory` function processes all `.html` files in a specified directory, applying these checks and optionally fixing issues using the `sanitize_summary` function from the `llm_client` module. The `main` function sets up command-line arguments to specify the directory to review and whether to enable autofixing of detected issues.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>This module provides a function to recursively discover Python (``.py``) and Objective-C (``.m``) source files within a specified directory. It includes an ignore mechanism based on relative paths, allowing certain directories or files to be excluded from the search. The function returns a list of absolute paths to the discovered source files, sorted alphabetically.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a><br/><small>A Python module that uses the `setuptools` library to define and execute a package setup.</small></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>This module provides functions for summarizing text using a language model client and caching the results. It includes:

1. `_summarize`: A helper function that summarizes text by calling the LLMClient and caching the result.
2. `summarize_chunked`: A main function that handles chunking large texts if necessary, then summarizes each chunk and merges them into a single summary.

The module uses utilities from `cache`, `chunk_utils`, and `llm_client` modules to manage caching, text chunking, and interacting with the language model.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>The module defines two functions for testing a response cache. The first function, `test_cache_round_trip`, tests setting and retrieving a value from the cache. It creates a temporary cache file, sets a key-value pair in the cache, and then retrieves it to ensure the value is correctly stored and retrieved.

The second function, `test_cache_get_missing`, tests retrieving a non-existent key from the cache. It creates an empty cache file and attempts to retrieve a value for a non-existent key, expecting `None` as the result.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>The module defines unit tests for functions `get_tokenizer` and `chunk_text`. The tests verify that the tokenizer encodes and decodes text correctly, that the text is reconstructed from chunks without loss, that markdown headings are split appropriately, and that code blocks are preserved across chunk boundaries.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>This module contains unit tests for a Python script that generates documentation from source code using an LLM (Large Language Model). The tests cover various scenarios, including:

1. Skipping invalid Python files.
2. Generating summaries for classes and functions.
3. Handling non-UTF8 encoded files.
4. Summarizing modules without docstrings.
5. Sanitizing project summaries.
6. Using README content as a summary.
7. Cleaning the output directory before generating new documentation.
8. Splitting long texts into chunks to fit within context token limits.
9. Recursively chunking text when prompt overhead exceeds available tokens.
10. Keeping functions atomic during structured chunking.
11. Splitting large classes by method during structured chunking.
12. Summarizing methods in subclasses.

The tests use the `unittest.mock` library to patch dependencies and verify that the main function (`docgenerator.main`) behaves as expected under different conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>The module defines a test function `test_subclass_docs_and_method_summary` that uses the `unittest.mock.patch` decorator to mock an `LLMClient` class from the `docgenerator` module. It sets up a temporary project directory with a Python file containing a subclass and a method, then calls the `main` function from `docgenerator` with the project directory path and an output directory path. The test asserts that the return value of `main` is 0, indicating success. It also checks that the generated HTML file contains summaries for the class and method, as specified by the mock client&#x27;s side effect.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>The module defines several functions and tests for creating documentation summaries, extracting text from files, rendering HTML, and handling different file formats. It includes a fixture creation function `_create_fixture`, a mock language model client `_mock_llm_client`, and various test cases to ensure functionality across Markdown, HTML, and DOCX files. The module also handles the extraction of snippets, code scanning, and evidence mapping for documentation sections.

The module contains several test functions for a code documentation tool using `pytest` fixtures like `tmp_path`, `monkeypatch`, and `caplog`. It mocks various functions in the `explaincode` module to simulate different scenarios, such as collecting documentation, ranking files, extracting snippets, and interacting with an LLM client. The tests cover categorizing code snippets into sections, filling placeholders in a manual using evidence from code snippets, generating full documentation without scanning code if not needed, triggering code fallback when specific sections are missing, handling the `--no-code` and `--force-code` flags, customizing the title and filename of the output, inserting generated documentation into an existing index file, and ensuring proper insertion of the documentation into a root index file. The tests validate that the tool behaves as expected under various conditions, including mocking external dependencies and handling different user inputs and configurations.

Additionally, this module contains several test functions for a summarization process, each testing different aspects of the summarization logic, such as chunking, merging, caching, and handling system prompts.</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>The module defines functions to generate HTML documentation for projects and modules. It includes tests to ensure the HTML output is correct, covering various cases such as rendering summaries, classes, methods, functions, subfunctions, and subclasses in a structured format.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>The module defines two test functions for a documentation generator. The first function, `test_docgenerator_generates_html`, tests the generation of HTML files from Python and MATLAB files in a project directory using a mock LLMClient. It asserts that the correct HTML files are created and contains the expected summary text.

The second function, `test_static_copied_from_any_cwd`, tests the copying of static files (e.g., style.css) to the output directory regardless of the current working directory. It uses a mock LLMClient and asserts that the static file is correctly copied to the output directory.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>The module defines a test suite for an `LLMClient` class, which interacts with a language model. It includes tests for the `ping`, `summarize`, and `sanitize_summary` methods of the client. The tests use mocking to simulate HTTP requests and responses, ensuring that the client behaves as expected under various conditions, including successful and failed connections, retries, and error handling. Additionally, it verifies that prompts sent to the language model vary based on the type of content being summarized (e.g., class, function, readme).</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>The module defines two functions: `_count` and `test_chunk_docs_respects_token_limit`, `test_find_placeholders`. The `_count` function calculates the number of tokens in a given text using a tokenizer from the `manual_utils` module. The `test_chunk_docs_respects_token_limit` function tests the `chunk_docs` function from `manual_utils` to ensure it respects a token limit by splitting documents into chunks and verifying their sizes. The `test_find_placeholders` function tests the `find_placeholders` function from `manual_utils` to ensure it correctly identifies placeholders in a text.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>The module defines two test functions to verify the functionality of a MATLAB file parser. The `test_parse_simple_matlab` function checks if the parser correctly extracts the header and a single function from a simple MATLAB file. The `test_parse_multiple_functions` function tests the parser&#x27;s ability to handle multiple functions within a MATLAB file, verifying both the presence of all functions and their argument lists.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>The module defines several test functions to verify the functionality of a `parse_python_file` function. Each test function creates a temporary Python file with different structures (simple modules, complex signatures, nested classes) and asserts that the `parse_python_file` function correctly parses these structures into a dictionary containing information about modules, classes, methods, and functions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>This module defines several functions and tests for a code review tool. It includes:

1. `_make_module`: Creates a temporary module with specified summary and methods, writes an HTML page for it, and returns the path to the HTML file.
2. `test_assistant_phrasing_detected`: Tests if the assistant phrasing is detected in the module&#x27;s summary.
3. `test_contradiction_detected`: Tests if a contradiction is detected when methods are defined but not described.
4. `test_hallucination_detected`: Tests if a hallucination is detected when the module claims to implement features that are not present.
5. `test_autofix_removes_phrasing`: Tests if the autofix option removes phrasing from the HTML output.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>The module defines a test suite for the `scan_directory` function from the `scanner` module. It includes three tests:

1. **test_scan_directory_ignore_folder**: Creates a directory structure with files and a subdirectory named &quot;ignore_me&quot;. Calls `scan_directory` with this path and a list containing &quot;ignore_me&quot; to ignore it. Asserts that only non-ignored files are returned.

2. **test_scan_directory_mixed_file_types**: Creates a directory structure with various file types (Python, Objective-C, text). Calls `scan_directory` without ignoring any folders. Asserts that all non-hidden files of supported types are returned.

3. **test_scan_directory_skips_git_folder**: Creates a directory structure including a hidden `.git` folder and its contents. Calls `scan_directory` without ignoring any folders. Asserts that the `.git` folder and its contents are not included in the result.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
