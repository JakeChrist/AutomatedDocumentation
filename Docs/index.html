<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul><li><a href="cache.html">cache</a></li><li><a href="chunk_utils.html">chunk_utils</a></li><li><a href="docgenerator.html">docgenerator</a></li><li><a href="explaincode.html">explaincode</a></li><li><a href="gui_wrapper.html">gui_wrapper</a></li><li><a href="html_writer.html">html_writer</a></li><li><a href="llm_client.html">llm_client</a></li><li><a href="manual_utils.html">manual_utils</a></li><li><a href="parser_cpp.html">parser_cpp</a></li><li><a href="parser_java.html">parser_java</a></li><li><a href="parser_matlab.html">parser_matlab</a></li><li><a href="parser_python.html">parser_python</a></li><li><a href="retrofit_sidebar.html">retrofit_sidebar</a></li><li><a href="reviewer.html">reviewer</a></li><li><a href="sanitize_docs.html">sanitize_docs</a></li><li><a href="scanner.html">scanner</a></li><li><a href="setup.html">setup</a></li><li><a href="summarize_utils.html">summarize_utils</a></li><li><details><summary>tests</summary><ul><li><a href="test_cache.html">test_cache</a></li><li><a href="test_chunk_utils.html">test_chunk_utils</a></li><li><a href="test_docgenerator.html">test_docgenerator</a></li><li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li><li><a href="test_explaincode.html">test_explaincode</a></li><li><a href="test_html_writer.html">test_html_writer</a></li><li><a href="test_integration.html">test_integration</a></li><li><a href="test_llm_client.html">test_llm_client</a></li><li><a href="test_manual_utils.html">test_manual_utils</a></li><li><a href="test_parser_cpp.html">test_parser_cpp</a></li><li><a href="test_parser_java.html">test_parser_java</a></li><li><a href="test_parser_matlab.html">test_parser_matlab</a></li><li><a href="test_parser_python.html">test_parser_python</a></li><li><a href="test_resume_progress.html">test_resume_progress</a></li><li><a href="test_reviewer.html">test_reviewer</a></li><li><a href="test_sanitize_docs.html">test_sanitize_docs</a></li><li><a href="test_scanner.html">test_scanner</a></li></ul></details></li></ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM generates static HTML documentation for Python, MATLAB, C++, and Java projects by analyzing source files with a local LLM. It supports nested functions and subclasses, rendering complex structures as expandable sections in the output. The tool includes CLI and GUI options for customization, progress saving, and language support. Additionally, it provides utilities for sanitizing existing documentation, retrofitting sidebars, and generating project summaries.
The project consists of multiple modules for various functionalities related to code documentation and summarization. The `cache.py` module provides a caching mechanism for responses. The `chunk_utils.py` module includes utilities for chunking text into manageable parts. The `docgenerator.py` module handles the generation of summaries for Python code, including class and function summaries. The `explaincode.py` module is responsible for collecting documentation, parsing code files, and generating user manuals using an LLM (Language Model). The `gui_wrapper.py` module provides a graphical user interface for interacting with the code summarization tools. The `html_writer.py` module generates HTML content from parsed code. The `llm_client.py` module interfaces with an LLM to generate summaries and sanitize them. The `manual_utils.py` module includes utilities for handling manual documents, such as chunking and finding placeholders. Various parser modules (`parser_cpp.py`, `parser_java.py`, etc.) are responsible for parsing different programming languages. The `retrofit_sidebar.py` module modifies a sidebar with documentation information. The `reviewer.py` module reviews generated documentation for quality issues. The `sanitize_docs.py` module sanitizes HTML files to remove AI-generated disclaimers and other unwanted content. The `scanner.py</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>A simple on-disk cache for Language Model (LLM) responses. Implements methods to store and retrieve LLM responses using deterministic keys derived from file paths and content. Includes functionality to manage progress data for processed modules. Cache is persisted to disk in JSON format.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>The module provides utility functions for tokenization and text chunking. It includes:

1. `strip_fim_tokens(text: str) -&gt; str`: Removes FIM special tokens from the input text.
2. `get_tokenizer()`: Returns a tokenizer object used for estimating token counts, using `tiktoken` if available or a simple character-based tokenizer otherwise.
3. `_split_blocks(text: str) -&gt; List[str]`: Splits Markdown text into paragraphs, headings, and fenced code blocks.
4. `_split_long_block(block: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: Fallback splitter that uses a character-based approximation to split long blocks exceeding the specified token size.
5. `chunk_text(text: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: Splits text into chunks roughly of the specified token size, honoring natural break points like blank lines, Markdown headings, and fenced code blocks. If a single block exceeds the token size, it falls back to splitting by approximate character length.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>This module provides a command-line interface for generating HTML documentation from source code files. It scans directories for Python, MATLAB, C++, and Java files, parses them, requests summaries from a running language model (LLM), and writes the summaries to HTML files. The module includes functions for summarizing classes and methods recursively, rewriting docstrings with context, and parsing various programming languages. It handles command-line arguments for specifying the source directory, output directory, and other options. The script processes Python, C++, Java, and MATLAB files, generating summaries and HTML pages based on the parsed data.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>This module provides a comprehensive system for generating project summaries from existing documentation and sample files. It includes classes and functions for parsing configuration, collecting relevant files, slugifying text, inserting links into indices, extracting text from various file types, detecting placeholders, mapping evidence to sections, ranking code files, and more. Specifically, it offers functionalities such as `extract_snippets` to extract code snippets from specified files within given constraints, `scan_code` to collect source code snippets from a base directory grouped by manual sections based on predefined keywords, and `llm_generate_manual` to generate a user manual from collected documentation snippets using an LLM. Additionally, it provides utilities for rendering HTML from structured sections of a manual, parsing plain text into structured sections, validating references within sections, inferring missing sections, and converting HTML to PDF. The module also interacts with an LLMClient for generating summaries and inferring missing sections when required. Finally, the `main` function sets up command-line arguments for summarizing project documentation, collects documentation files, extracts text from them, generates a manual using an LLM client, fills placeholders if necessary, renders the manual in HTML or PDF format, inserts a link to the manual into an index file if specified, and saves the evidence map as a</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>A PyQt5 application for running DocGen and ExplainCode tools. Features include:</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>This module provides utilities for rendering documentation pages using simple template substitution. It includes functions for rendering navigation trees, highlighting code snippets, and generating HTML content based on structured data representing project modules, classes, methods, and variables. The module also includes functions to write index and module-specific documentation pages to output directories.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>This module provides an interface to a local language model backend (LMStudio) for generating summaries of code files. It includes:</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>This module provides functions for splitting text into chunks, summarizing documents using a language model, and merging summaries. It includes utilities for token counting, text chunking based on token limits, finding placeholder tokens, and caching responses to avoid redundant requests to an LLM (Language Model). The module uses concurrent processing with `ThreadPoolExecutor` to handle multiple summarization tasks in parallel.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_cpp.html">parser_cpp</a><br/><small>This Python module provides a simple parser for C++ files used by DocGen-LM. It employs line-based parsing to extract namespaces, classes, functions, and public variables from the source code. The parser returns a structured dictionary containing `module_docstring`, `classes`, and `functions`. Each class and function includes their respective `source` snippets and any leading documentation comments.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_java.html">parser_java</a><br/><small>This Python module provides a simple parser for Java files used by DocGen-LM. It extracts the package name, classes, public methods, and variables from Java source code using naive line-based parsing. The output mirrors the structure of `parse_python_file`, with keys for `module_docstring`, `classes`, and `functions`. Each class entry includes its source code and leading documentation comments (Javadoc or `//`).</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>The module provides a function `parse_matlab_file` that parses MATLAB `.m` files and extracts basic structure. It reads the file content, identifies leading comment lines as the file header, and uses regular expressions to find and parse function declarations, extracting their names and arguments. The result is returned as a dictionary containing the file header comments and a list of functions with their respective argument lists.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>This module provides a parser for Python files using the `ast` module. It extracts structured information about classes and functions according to the Software Requirements Specification (SRS). The parser can handle both synchronous and asynchronous functions. It includes utilities to format function signatures, parse class definitions, and recursively parse nested classes and functions within a Python file. The main entry point is `parse_python_file`, which takes a file path as input and returns a dictionary containing module docstring, classes, and functions with detailed information such as names, signatures, return types, docstrings, source code segments, subfunctions, and subclasses.</small></li>
<li style="margin-bottom: 1em;"><a href="retrofit_sidebar.html">retrofit_sidebar</a><br/><small>This module defines a script to replace documentation sidebars with a hierarchical module list. It includes functions for converting file paths into a nested dictionary tree and recursively building unordered lists from this tree. The `retrofit_sidebar` function scans a source directory for Python modules, constructs a hierarchical structure, and updates HTML files in the documentation directory by replacing existing sidebars with the new hierarchical module list. The script is executed via the command line with optional arguments for specifying the source root directory and the documentation directory.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>This module provides a tool to review HTML documentation generated by DocGen-LM. It includes functions to check for assistant-like phrases, contradictions, and hallucinations in the HTML content. The `check_assistant_phrasing` function identifies paragraphs containing specific phrases that may indicate automated assistance. The `check_contradictions` function looks for inconsistencies between the summary and actual documented elements like methods, functions, and classes. The `check_hallucinations` function searches for terms that are unlikely to appear in documentation, such as game titles or food recipes. The module also provides a command-line interface (`main`) to review all HTML files in a specified directory and optionally fix issues by sanitizing the paragraphs using a function from `llm_client`.</small></li>
<li style="margin-bottom: 1em;"><a href="sanitize_docs.html">sanitize_docs</a><br/><small>This module provides a script to sanitize existing HTML documentation. It defines functions to sanitize individual HTML files and entire directories containing HTML files. The sanitization process involves removing unwanted tags from the content within specific HTML elements (like `&lt;p&gt;`, `&lt;li&gt;`, and headers) and then applying a summary sanitization function (`sanitize_summary` from `llm_client`) to the cleaned content. The script can be run as a command-line tool, accepting a directory path as an argument.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>This module provides a function to recursively discover source files within a directory structure. It supports ignoring specified paths and can optionally display a progress bar during the scan. The supported file extensions are `.py`, `.m`, `.cpp`, `.h`, and `.java`. The function returns a sorted list of absolute paths to the discovered source files.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a><br/><small>This Python script uses `setuptools` to define a package with three modules: `explaincode`, `parser_cpp`, and `parser_java`. It includes a conditional block that runs the `setup` function from `setuptools` when the script is executed directly.</small></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>This module provides functions for summarizing text using a language model client, with caching to avoid redundant requests. It includes:

1. `_summarize`: Summarizes a single piece of text.
2. `summarize_chunked`: Sums up large pieces of text by breaking them into smaller chunks and then recursively merging the summaries.

The module uses a tokenizer for tokenization operations, handles caching to store previously summarized texts, and manages chunking and merging processes to ensure efficient summarization even for long texts.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>This module defines a `ResponseCache` class for caching responses and progress data, along with test functions to verify its functionality. The `test_cache_round_trip` function checks that data can be set and retrieved from the cache. The `test_cache_get_missing` function verifies that attempting to retrieve a non-existent key returns `None`. The `test_progress_tracking` function tests setting and clearing progress data in the cache.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>The module contains tests for a tokenizer and a text chunking utility. The tokenizer is expected to encode and decode text correctly, stripping finalization tokens while preserving spaces. The text chunking function should split text into chunks of a specified length, ensuring that markdown headings and code blocks are not broken across chunks.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>The module contains unit tests for a documentation generation tool. It uses the `unittest.mock` library to patch dependencies and test various scenarios, such as handling invalid Python files, generating summaries for classes and functions, skipping non-UTF8 files, and processing different types of source files like C++, Java, and Python. The tests ensure that the tool correctly identifies and processes code elements, generates summaries using an LLMClient, and handles edge cases gracefully.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>The module defines a test function `test_subclass_docs_and_method_summary` that uses the `unittest.mock.patch` decorator to mock an `LLMClient`. It sets up a temporary project directory with a Python file containing a class hierarchy. The `main` function from the `docgenerator` module is called with this project directory and an output directory specified. The test asserts that the return value of `main` is 0, indicating success. It then checks that the generated HTML documentation contains summaries for the class &quot;B&quot; and its method &quot;m&quot;, as well as a placeholder &quot;docstring summary&quot;.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>The module provides functions for creating test fixtures, mocking an LLM client, and running tests related to text extraction, HTML rendering, and document processing. It includes tests for extracting text from Markdown, HTML, and DOCX files, rendering HTML with sections and evidence, creating user manuals in both HTML and PDF formats, handling missing dependencies gracefully, and inferring section content when information is missing. Additionally, the module contains test functions for a code documentation tool named `explaincode`, covering aspects such as categorizing code snippets, ranking code files, filling placeholders, skipping code scanning, fallback mechanisms based on flags, and handling large texts through chunking, merging, caching, and logging.</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>The module defines functions to generate HTML documentation for Python modules and packages. It includes tests to ensure the generated HTML is correct, including proper rendering of classes, methods, variables, and subfunctions. The `_highlight` function is used to syntax-highlight code snippets in C++ and Java.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>The module defines two test functions for a documentation generator. The first function, `test_docgenerator_generates_html`, tests the generation of HTML documentation from various file types (Python, MATLAB, C++, Java) using a mock LLMClient. It asserts that the output directory contains HTML files for each input file and that the summary text is present in these files.

The second function, `test_static_copied_from_any_cwd`, tests the copying of static assets (like `style.css`) to the output directory regardless of the current working directory. It uses a mock LLMClient and asserts that the static asset is copied successfully to the output directory.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>The code defines a test suite for an `LLMClient` class, which interacts with a language model. The tests cover the following functionalities:

1. **Ping Method**: Tests that the `ping` method successfully checks connectivity to the language model server.
2. **Summarize Method**:
3. **Sanitize Summary Function**: Tests that the `sanitize_summary` function filters out unwanted phrases, FIM tokens, and prompt lines from the input text.

The tests use mocking to simulate HTTP responses and verify that the methods behave as expected under different conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>The module defines two functions: `_count` and `test_chunk_docs_respects_token_limit`, `test_find_placeholders`. The `_count` function calculates the number of tokens in a given text using a tokenizer from the `manual_utils` module. The `test_chunk_docs_respects_token_limit` function tests the `chunk_docs` function from `manual_utils` to ensure it chunks documents without exceeding a specified token limit. The `test_find_placeholders` function checks if the `find_placeholders` function correctly identifies placeholders in a given text.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_cpp.html">test_parser_cpp</a><br/><small>The module defines a test function `test_parse_cpp` that uses the `parse_cpp_file` function from the `parser_cpp` module to parse a C++ source file. The test checks if the parsed result contains the expected documentation strings, namespace, functions, and classes. It verifies the correctness of the parsed data by comparing it with predefined assertions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_java.html">test_parser_java</a><br/><small>The module defines a test function `test_parse_java` that uses the `parse_java_file` function from the `parser_java` module to parse a Java source file. The test checks if the parsed result contains the correct package, class, field, and method information extracted from the Java code.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>The module provides unit tests for a MATLAB file parser. It includes two test functions: `test_parse_simple_matlab` and `test_parse_multiple_functions`. Each function creates a temporary MATLAB file with specific content, parses it using the `parse_matlab_file` function from the `parser_matlab` module, and asserts that the parsed result matches expected values. The tests check for correct parsing of function names, arguments, and headers in MATLAB files.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>This module contains tests for parsing Python files using the `parse_python_file` function from the `parser_python` module. It includes several test cases to verify the correctness of the parser, covering various scenarios such as simple modules, complex function signatures, nested structures, deeply nested classes, and class definitions inside methods. Each test case creates a temporary Python file with specific content, parses it using `parse_python_file`, and asserts that the parsed results match the expected structure and attributes of the code.</small></li>
<li style="margin-bottom: 1em;"><a href="test_resume_progress.html">test_resume_progress</a><br/><small>The module defines a test function `test_resume_progress` that uses the `pytest` framework to verify the behavior of the `docgenerator.main` function. It sets up a temporary project directory with two Python modules, mocks several functions from the `docgenerator` and `cache` modules to simulate their behavior during testing, and tests the main function&#x27;s ability to resume progress after encountering an error. The test asserts that the function correctly handles errors, resumes processing, and generates documentation for modules as expected.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>This module defines a set of tests to detect and handle specific issues in Python modules. It includes functions to create temporary module files, run a main function with these files, and check for the presence of certain phrases indicating issues like assistant phrasing, contradictions, or hallucinations. The module also contains a test function that demonstrates how to use these features to automatically fix detected issues by removing specific phrases from the HTML output.</small></li>
<li style="margin-bottom: 1em;"><a href="test_sanitize_docs.html">test_sanitize_docs</a><br/><small>This module contains tests for a utility named `sanitize_docs`. It includes two test functions:

1. **test_sanitize_directory_removes_ai_disclaimer**: This function tests the removal of an AI disclaimer from HTML content within a directory. It creates a temporary file with HTML content containing an AI disclaimer and another paragraph. After running the `main` function, it checks that the AI disclaimer has been removed, while other content remains unchanged.

2. **test_sanitize_directory_handles_headings_and_list_items**: This function tests handling of headings and list items in HTML content within a directory. It creates a temporary file with HTML content containing an AI disclaimer in a heading and another paragraph in a list item. After running the `main` function, it checks that both the AI disclaimer and the text &quot;You can run this&quot; have been removed, while other content remains unchanged.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>The module defines a function `scan_directory` from the `scanner` module and tests for its functionality using `pytest`. It includes tests to verify that directories can be ignored, mixed file types are included, `.git` folder is skipped, and various programming languages&#x27; files (Python, Objective-C, Java, C++, C) are correctly identified.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
