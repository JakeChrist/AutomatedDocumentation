<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul>
        <li><a href="cache.html">cache</a></li>
<li><a href="chunk_utils.html">chunk_utils</a></li>
<li><a href="docgenerator.html">docgenerator</a></li>
<li><a href="explaincode.html">explaincode</a></li>
<li><a href="gui_wrapper.html">gui_wrapper</a></li>
<li><a href="html_writer.html">html_writer</a></li>
<li><a href="llm_client.html">llm_client</a></li>
<li><a href="manual_utils.html">manual_utils</a></li>
<li><a href="parser_cpp.html">parser_cpp</a></li>
<li><a href="parser_java.html">parser_java</a></li>
<li><a href="parser_matlab.html">parser_matlab</a></li>
<li><a href="parser_python.html">parser_python</a></li>
<li><a href="reviewer.html">reviewer</a></li>
<li><a href="scanner.html">scanner</a></li>
<li><a href="setup.html">setup</a></li>
<li><a href="summarize_utils.html">summarize_utils</a></li>
<li><a href="test_cache.html">test_cache</a></li>
<li><a href="test_chunk_utils.html">test_chunk_utils</a></li>
<li><a href="test_docgenerator.html">test_docgenerator</a></li>
<li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li>
<li><a href="test_explaincode.html">test_explaincode</a></li>
<li><a href="test_html_writer.html">test_html_writer</a></li>
<li><a href="test_integration.html">test_integration</a></li>
<li><a href="test_llm_client.html">test_llm_client</a></li>
<li><a href="test_manual_utils.html">test_manual_utils</a></li>
<li><a href="test_parser_cpp.html">test_parser_cpp</a></li>
<li><a href="test_parser_java.html">test_parser_java</a></li>
<li><a href="test_parser_matlab.html">test_parser_matlab</a></li>
<li><a href="test_parser_python.html">test_parser_python</a></li>
<li><a href="test_reviewer.html">test_reviewer</a></li>
<li><a href="test_scanner.html">test_scanner</a></li>
        </ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM is a tool for generating static HTML documentation for Python, MATLAB, C++, and Java projects by analyzing source files with a local LLM. It supports nested functions and subclasses, rendering complex structures as expandable sections in the output. The tool includes both command-line interface (CLI) and graphical user interface (GUI) usage options, allowing users to specify project directories, output locations, and other parameters. Additionally, it provides a utility called `explaincode.py` for generating lightweight project summaries and documentation, with options for chunking text based on token or character limits.
This project includes a suite of tools for generating and summarizing documentation from source code. It features classes and functions for caching responses, chunking text into manageable pieces, parsing various programming languages (Python, Java, C++, MATLAB), summarizing code structures, and interacting with an LLM to generate summaries. The GUI wrapper provides a user interface for selecting directories and files, running commands, and displaying logs. Utilities are included for handling HTML rendering, manual parsing, and code review. The project also contains extensive testing to ensure functionality across different languages and scenarios.</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>A simple on-disk cache for LLM responses. Implements methods to initialize the cache from a file, generate deterministic keys based on file paths and content, retrieve cached values, store new values with persistence to disk, and save the current state of the cache to a file.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>The module provides utility functions for tokenization and text chunking. It includes:

1. `get_tokenizer()`: Returns a tokenizer object used for estimating token counts, defaulting to a simple character-based tokenizer if `tiktoken` is not installed or fails.

2. `_split_blocks(text: str) -&gt; List[str]`: Splits Markdown text into paragraphs, headings, and fenced code blocks.

3. `_split_long_block(block: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: Fallback splitter that splits a block by approximate character length if it exceeds the specified token size.

4. `chunk_text(text: str, tokenizer, chunk_size_tokens: int) -&gt; List[str]`: Splits text into chunks roughly of the specified token size, honoring natural break points like blank lines, Markdown headings, and fenced code blocks. Falls back to character-based splitting for blocks exceeding the token size.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>The script defines a process to generate HTML documentation using a local language model (LLM). It includes functions such as `clean_output_dir` to clean up existing HTML files, `_summarize` to summarize text with caching, `_chunk_module_by_structure` and `_summarize_module_chunked` for handling token limits by chunking module text, `_build_function_prompt` to create context-enriched prompts for summarizing code, `_rewrite_docstring` to update docstrings using optional context, and `_summarize_members_recursive` to recursively summarize methods and variables within classes and subclasses. The script utilizes a cache to store previously generated summaries to avoid redundant requests to the LLM. It processes files in a specified source directory, summarizes modules, and generates project-level summaries, ultimately writing HTML documentation pages for each module and updating docstrings with context from the project summary.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>This module defines a `Config` class for holding configuration settings parsed from CLI arguments. It includes functions for collecting documentation and code files from a project directory, as well as utilities for slugifying text, inserting links into an index file, and extracting plain text from various file types. The module also provides logic to detect placeholders in text and map evidence snippets to manual sections.

The core functionality involves:
1. Extracting relevant code snippets from files using `extract_snippets`, categorizing them by sections with `scan_code`.
2. Generating a manual from documentation snippets using an LLM client with `llm_generate_manual`.
3. Filling placeholder tokens in the manual text with code snippets using `llm_fill_placeholders`.
4. Optionally editing chunks of text in the user&#x27;s editor with `_edit_chunks_in_editor`.

Additionally, this module offers functions for rendering HTML from structured sections of a manual (`render_html`), parsing text into structured sections (`parse_manual`), validating references within those sections (`validate_manual_references`), inferring missing sections (`infer_sections`), and writing the rendered HTML as a PDF using ReportLab with `write_pdf`.

The main function, `main`, serves as the entry point for summarizing project documentation. It processes command-line arguments to create a `Config` object, collects documentation files, extracts text, logs the process, initializes an LLM client, generates a manual, fills placeholders, parses sections, validates references, renders output in HTML or PDF format, inserts links into an index file if requested, and saves evidence data. It handles exceptions gracefully and returns 0 upon successful completion.</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>A Python application using PyQt5 for a graphical user interface (GUI) to run documentation and code explanation tools. The application includes:

1. A `PathLineEdit` class for file path input with drag-and-drop functionality.
2. A `CollapsibleBox` class for creating collapsible sections in the GUI.
3. A `CommandRunner` class that runs shell commands asynchronously, emitting output and completion signals.
4. A `MainWindow` class that sets up the GUI layout, handles user interactions, and manages running documentation and code explanation tools.

The main functionality includes:
- Selecting project and output directories.
- Configuring options for DocGen (documentation generation) and ExplainCode (code explanation).
- Running DocGen, ExplainCode, or both in sequence.
- Displaying log output of the commands run.</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>This module provides utilities for rendering documentation pages using simple template substitution. It includes functions for highlighting code snippets in various programming languages and for generating HTML content based on structured data representing project summaries, modules, classes, methods, and variables. The module also includes functions to write index and module-specific documentation pages to an output directory.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>This module provides an interface to communicate with a local language model (LMStudio) for generating summaries. It includes:

- A `SYSTEM_PROMPT` defining the behavior of the documentation engine.
- Common rules for prompt templates.
- A `README_PROMPT` for enriching project summaries from README files.
- A dictionary `PROMPT_TEMPLATES` containing different types of prompts for summarizing modules, classes, functions, and more.
- A `sanitize_summary` function to clean up generated summaries by removing unwanted phrases.
- An `LLMClient` class that acts as a thin wrapper around the LMStudio HTTP API:
- Initializes with a base URL and model name.
- Includes a `ping` method to check if the API is reachable.
- Implements a `summarize` method to generate summaries for given text using specified prompt types, handling retries on failures.</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>This module provides functions for splitting text into chunks and generating summaries using a language model. It includes:

1. `_count_tokens`: Counts the number of tokens in a given text.
2. `_split_text`: Splits text into chunks based on token and character limits.
3. `chunk_docs`: Splits a list of documents into roughly equal-sized chunks.
4. `find_placeholders`: Finds placeholder tokens in a given text.
5. `_summarize_manual`: Generates a summary for a given text using a chunking strategy, utilizing an LLMClient for summarization and a ResponseCache for caching responses.

The module uses concurrent processing with ThreadPoolExecutor to handle multiple chunks simultaneously, improving efficiency when dealing with large texts.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_cpp.html">parser_cpp</a><br/><small>This Python module provides a simple parser for C++ files, designed to extract namespaces, classes, functions, and public variables. It returns a structured dictionary compatible with `parse_python_file`, containing `module_docstring`, `classes`, and `functions`. Each item in these lists includes its source code snippet and any leading documentation comments. The module uses line-based parsing techniques to identify class bodies, method signatures, variable declarations, and namespace definitions within C++ files.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_java.html">parser_java</a><br/><small>A simple parser for Java files used by DocGen-LM. Extracts package, classes, public methods, and variables using naive line-based parsing. The output mirrors `parse_python_file` with keys `module_docstring`, `classes`, and `functions`. Each entry includes its source code and leading documentation comments (Javadoc or `//`).</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>This module provides a function `parse_matlab_file` that parses MATLAB `.m` files and extracts basic structure. It reads the file content, identifies leading comment lines as the file header, and uses a regular expression to find and extract function declarations along with their arguments. The result is returned as a dictionary containing the file header and a list of functions, each represented by its name and argument list.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>This module provides a parser for Python files used by DocGen-LM. It uses the `ast` module to extract structures according to the SRS. The parser can parse Python source files and return structured information about the module&#x27;s docstring, classes, and functions. Each class and function is represented as a dictionary containing details such as name, signature, returns, docstring, source code, subfunctions/subclasses, and more.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>This module provides a tool to review HTML documentation generated by DocGen-LM. It includes functions to check for assistant-like phrases, contradictions, and hallucinations in the HTML content. The `review_directory` function processes all `.html` files in a specified directory, applying these checks and optionally fixing issues by sanitizing paragraphs using a `sanitize_summary` function from an external library (`llm_client`). The tool can be run from the command line with options to specify the directory path and enable autofix mode.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>The module implements a function to recursively discover source files of specific types (`.py`, `.m`, `.cpp`, `.h`, `.java`) within a given directory. It includes an ignore mechanism based on relative paths, allowing certain directories or files to be excluded from the search. The function returns a sorted list of absolute paths to the discovered source files.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a><br/><small>This Python script uses `setuptools` to define a package with three modules: `explaincode`, `parser_cpp`, and `parser_java`. The `setup()` function is called directly when the script is executed, which configures and installs the specified modules.</small></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>This module provides functions for summarizing text using a language model client and caching responses. It includes:

1. `_summarize`: Summarizes text directly if it fits within the context token limit, otherwise raises an exception.
2. `summarize_chunked`: Sums up text by breaking it into chunks if necessary, then recursively merges summaries of these chunks into a single technical paragraph.

Both functions utilize a caching mechanism to store and retrieve previously computed summaries, reducing redundant computations.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>This module defines two tests for a `ResponseCache` class. The first test, `test_cache_round_trip`, checks that data can be correctly set and retrieved from the cache file. It uses a temporary path to create a cache file, sets a key-value pair in the cache, reads it back, and asserts that the value matches the expected summary.

The second test, `test_cache_get_missing`, verifies that attempting to retrieve a non-existent key from the cache returns `None`. It creates an empty cache file, attempts to get a value for a missing key, and asserts that the result is `None`.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>The module defines several test functions to validate the functionality of `get_tokenizer` and `chunk_text`. The tests ensure that:

1. The tokenizer correctly encodes and decodes text.
2. The text is chunked appropriately without losing content.
3. Markdown headings are split into separate chunks.
4. Code blocks are preserved across chunk boundaries.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>The module contains unit tests for a code documentation generator. It uses the `unittest.mock` library to patch dependencies and test various scenarios, such as handling invalid Python files, generating summaries for classes and functions, skipping non-UTF8 files, and processing different programming languages like C++, Java, and Python. The tests ensure that the generator correctly identifies and processes different types of code elements while skipping or sanitizing problematic files.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>The module defines a test function `test_subclass_docs_and_method_summary` that uses the `unittest.mock.patch` to mock an `LLMClient` from the `docgenerator` module. It sets up a temporary project directory with a Python file containing a class `A` with a nested class `B` and a method `m`. The test calls the `main` function from `docgenerator` with the project directory path and an output directory path. It asserts that the return value of `main` is 0, indicating success. The test then reads the generated HTML file in the output directory and checks for specific strings related to class and method summaries.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>The code defines several functions and tests for creating documentation summaries, extracting text from files, rendering HTML, and handling different file formats. It includes a fixture creation function `_create_fixture`, a mock LLM client `_mock_llm_client`, and various test functions to ensure the functionality works as expected. The tests cover Markdown, HTML, and DOCX file processing, as well as PDF output generation. Additionally, there are functions for inferring sections from text, detecting placeholders, parsing manual content, validating references, and extracting snippets from code files. The module also contains several test functions for a code documentation tool, testing aspects such as categorizing code snippets, ranking code files, filling placeholders in user manuals, and handling various command-line options. These tests use `pytest` fixtures to set up temporary directories and mock objects for dependencies like file operations and external API calls. Furthermore, the module includes test functions for a summarization process, covering chunking, merging, caching, and large text handling. These tests utilize a mock client to simulate LLM calls and validate system behavior under different conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>The module provides functions to generate HTML documentation for Python modules and classes. It includes:

1. `write_index`: Generates the main index page of a project, listing all modules with summaries.
2. `write_module_page`: Generates detailed pages for individual Python modules, including their summary, variables, classes, methods, and functions.
3. `_highlight`: Highlights code snippets in C++ and Java using syntax highlighting.

The module uses the `html_writer` module to perform the actual HTML generation. It includes tests to ensure that the generated HTML is correct and properly formatted.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>The module defines two test functions for a documentation generator. The first function, `test_docgenerator_generates_html`, tests the generation of HTML documentation from various file types (Python, MATLAB, C++, Java) within a project directory. It uses a mock LLMClient to simulate API responses and verifies that HTML files are created in the output directory with expected content.

The second function, `test_static_copied_from_any_cwd`, tests the copying of static assets (like CSS) from any current working directory to the output documentation directory. It also uses a mock LLMClient and asserts that the static file is present in the output directory.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>This module defines unit tests for an `LLMClient` class, which interacts with a language model. The tests cover the following functionalities:

1. **Ping Method**: Verifies that the `ping` method successfully checks connectivity to the language model server.
2. **Summarize Method**: Tests the `summarize` method&#x27;s ability to handle retries and return summaries. It also checks how it handles exceptions and errors from the language model.
3. **Sanitize Summary Function**: Ensures that the `sanitize_summary` function filters out unwanted phrases from the summary text.
4. **Prompt Templates**: Validates that the prompt templates for different types (class, function, readme) are correctly formatted and used.

The tests use mocking to simulate HTTP requests and responses, ensuring that the client behaves as expected under various conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>The module defines two functions: `_count` and `test_chunk_docs_respects_token_limit`, `test_find_placeholders`. The `_count` function calculates the number of tokens in a given text using a tokenizer from the `manual_utils` module. The `test_chunk_docs_respects_token_limit` function tests the `chunk_docs` function from the `manual_utils` module to ensure it respects a token limit by splitting documents into chunks that do not exceed the limit. The `test_find_placeholders` function tests the `find_placeholders` function from the `manual_utils` module to verify its ability to identify and return placeholders in a given text.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_cpp.html">test_parser_cpp</a><br/><small>This module defines a test function `test_parse_cpp` that uses the `parse_cpp_file` function from `parser_cpp.py` to parse a C++ source file. The test checks if the parsed data includes the correct module comment, namespace, functions, and classes, as well as their respective docstrings and source code snippets.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_java.html">test_parser_java</a><br/><small>This module defines a test function `test_parse_java` that uses the `parse_java_file` function from the `parser_java` module to parse a Java source file. The test checks if the parsed result contains the expected package, class, field, and method information.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>This module contains two test functions to verify the functionality of a MATLAB file parser. The `test_parse_simple_matlab` function checks if the parser correctly extracts the header and a single function from a simple MATLAB file. The `test_parse_multiple_functions` function tests the parser&#x27;s ability to handle multiple functions within a single MATLAB file, ensuring that each function is correctly identified and its arguments are accurately parsed.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>The module defines several test functions to verify the functionality of a `parse_python_file` function. Each test function creates a Python source file with different structures (simple modules, complex signatures, nested classes, deeply nested classes, and class inside methods), writes it to a temporary directory, and then parses it using `parse_python_file`. The tests assert that the parsed results match the expected structure and content of the source files.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>This module defines functions to test the detection of assistant phrasing, contradictions, and hallucinations in Python modules. It uses a temporary directory to create module pages with specified summaries and methods. The `main` function from the `reviewer` module is called to process these pages, which outputs messages indicating detected issues like assistant phrasing, contradictions, or hallucinations. Additionally, it includes a test for an autofix feature that removes certain phrases from the HTML output.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>The module defines a test suite for the `scan_directory` function from the `scanner` module. It includes tests to verify that:

1. The function correctly ignores specified folders.
2. The function returns all files of various types (Python, Objective-C, text).
3. The function skips the `.git` folder by default.
4. The function supports additional file extensions like C++, C headers, and Java.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
