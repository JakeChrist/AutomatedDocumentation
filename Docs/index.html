<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul>
        <li><a href="cache.html">cache</a></li>
<li><a href="chunk_utils.html">chunk_utils</a></li>
<li><a href="docgenerator.html">docgenerator</a></li>
<li><a href="explaincode.html">explaincode</a></li>
<li><a href="gui_wrapper.html">gui_wrapper</a></li>
<li><a href="html_writer.html">html_writer</a></li>
<li><a href="llm_client.html">llm_client</a></li>
<li><a href="manual_utils.html">manual_utils</a></li>
<li><a href="parser_cpp.html">parser_cpp</a></li>
<li><a href="parser_java.html">parser_java</a></li>
<li><a href="parser_matlab.html">parser_matlab</a></li>
<li><a href="parser_python.html">parser_python</a></li>
<li><a href="reviewer.html">reviewer</a></li>
<li><a href="scanner.html">scanner</a></li>
<li><a href="setup.html">setup</a></li>
<li><a href="summarize_utils.html">summarize_utils</a></li>
<li><a href="test_cache.html">test_cache</a></li>
<li><a href="test_chunk_utils.html">test_chunk_utils</a></li>
<li><a href="test_docgenerator.html">test_docgenerator</a></li>
<li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li>
<li><a href="test_explaincode.html">test_explaincode</a></li>
<li><a href="test_html_writer.html">test_html_writer</a></li>
<li><a href="test_integration.html">test_integration</a></li>
<li><a href="test_llm_client.html">test_llm_client</a></li>
<li><a href="test_manual_utils.html">test_manual_utils</a></li>
<li><a href="test_parser_cpp.html">test_parser_cpp</a></li>
<li><a href="test_parser_java.html">test_parser_java</a></li>
<li><a href="test_parser_matlab.html">test_parser_matlab</a></li>
<li><a href="test_parser_python.html">test_parser_python</a></li>
<li><a href="test_reviewer.html">test_reviewer</a></li>
<li><a href="test_scanner.html">test_scanner</a></li>
        </ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM generates static HTML documentation for Python, MATLAB, C++, and Java projects by analyzing source files with a local LLM. It captures and renders nested functions and subclasses as expandable sections, providing a detailed and organized overview of complex project structures.
This project appears to be a comprehensive code documentation tool that supports multiple programming languages. It includes modules for parsing different file types (Python, C++, Java, MATLAB), summarizing code and documentation, generating HTML and PDF summaries, and interacting with an LLM client for text generation. The system also features a GUI wrapper for user interaction and a caching mechanism to improve performance. Additionally, there are test modules to ensure the functionality works as expected across various scenarios.</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>A simple on-disk cache for LLM responses. Implements methods to initialize the cache from a file, generate deterministic keys based on file paths and content, retrieve cached values by key, store new values with associated keys, and persist the cache to disk in JSON format.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>This module provides utility functions for tokenization and text chunking. The `chunk_text` function splits text into chunks roughly of a specified size in tokens, preferring natural break points like blank lines, Markdown headings, and fenced code blocks. If a single block exceeds the token limit, it falls back to splitting by approximate character length. The `get_tokenizer` function returns a tokenizer object for estimating token counts, using `tiktoken` if available or falling back to a simple word-based tokenizer.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>This module provides a command-line interface for generating HTML documentation using DocGen-LM. It scans a source tree for Python, MATLAB, C++, and Java files, parses them, requests summaries from a running LLM, and writes the documentation. The module includes functions for cleaning output directories, summarizing text with caching, chunking modules by structure, summarizing modules in a structured manner, building context-enriched prompts, rewriting docstrings, and recursively summarizing members of classes and their subclasses. It defines a Python script that processes directories, ignores specified paths, handles file encoding errors, and uses command-line arguments for configuration, such as the source directory, output directory, ignored paths, LLM URL, model name, and token budget. The script reads files, parses them into structured data, generates summaries using the LLM, and writes HTML documentation pages.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>This module provides comprehensive functionality for generating project summaries from existing documentation and sample files. It includes classes, functions, and utilities for parsing configuration from CLI arguments, collecting documentation and code files based on specified patterns, generating slugs for filenames, inserting navigation entries into an index file, extracting plain text from various file types, detecting placeholders in text, mapping documentation snippets to manual sections, and ranking code files by heuristics. The module defines functions to extract relevant code snippets from files, categorize them by sections, and generate a manual using an LLM client. It includes:

1. `extract_snippets`: Extracts code snippets from given files based on file size, time budget, and specific conditions.
2. `scan_code`: Collects source code snippets from a base directory grouped by manual sections.
3. `llm_generate_manual`: Generates a manual from documentation snippets using an LLM client, mapping snippets to manual sections and assembling the final text.
4. `llm_fill_placeholders`: Fills placeholder tokens in a manual text using provided code snippets.
5. `_edit_chunks_in_editor`: Opens chunks of text in the user&#x27;s editor for optional modification.

These functions facilitate automated documentation generation and manual creation from source code, leveraging LLMs for content synthesis. The module also provides utilities to render HTML from structured sections of a manual, parse plain text into structured sections, validate references within sections, infer missing sections, and write HTML content as a PDF. It includes utilities for slugifying text, escaping HTML, and handling Markdown conversion. The module manages evidence snippets and missing references, ensuring that the rendered HTML reflects extracted documentation accurately.

The module defines a `main` function that sets up command-line arguments to configure project documentation summarization. It uses the `argparse` library to parse these arguments and create a `Config` object with the provided settings. The main function collects documentation files, reads their contents, and initializes logging based on the chunking mode. It creates an instance of an `LLMClient` for language model-based summarization and a `ResponseCache` for caching responses.

The main process involves two passes: the first to generate an initial manual summary using the language model, and the second to fill in any missing sections with code snippets if specified. The function handles exceptions during the LLM summarization process, falling back to manual section inference if necessary. Finally, it renders the HTML or PDF output based on the selected format, injects a link to the generated manual into an index file if requested, and saves evidence data for later reference.</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>A PyQt5 application for running DocGen-LM documentation tool and ExplainCode. Features include:

- A dark-themed GUI with a header, project/output directory selectors, options for DocGen and ExplainCode, and a log area.
- Custom widgets like `PathLineEdit` for file/directory selection and `CollapsibleBox` for organizing options.
- Multi-threaded command execution using `CommandRunner`, which handles output streaming and error handling.
- Buttons to run DocGen, ExplainCode, or both, with logging of the process.</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>This module provides HTML rendering utilities for DocGen-LM. It includes functions to highlight code snippets in various programming languages and to render documentation pages using simple template substitution. The module defines templates for index and module pages, which are populated with project summaries, page links, function descriptions, class definitions, and variable details. It uses Pygments for syntax highlighting and HTML for rendering the final output.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>This module provides an interface to a local language model (LLM) backend using the LMStudio HTTP API. It includes:

- A `sanitize_summary` function that removes unwanted phrases from a summary text.
- An `LLMClient` class that:
- Initializes with a base URL and model name.
- Includes a `ping` method to check if the LLM server is reachable.
- Implements a `summarize` method that sends a request to the LLM API using a specified prompt template, handles retries on failures, and sanitizes the response before returning it.</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>This module provides functions for splitting text into manageable chunks and generating summaries using a language model. It includes:

1. `_count_tokens`: Counts the number of tokens in a given text.
2. `_split_text`: Splits text into chunks based on token and character limits.
3. `chunk_docs`: Splits a list of documents into chunks.
4. `find_placeholders`: Identifies placeholder tokens in text.
5. `_summarize_manual`: Generates a summary for text using a specified chunking strategy, utilizing an LLMClient for summarization tasks.

The module uses caching to store and retrieve previously generated summaries to improve efficiency. It handles different chunking strategies (&quot;auto&quot;, &quot;manual&quot;, &quot;none&quot;) and includes error handling for network failures and other exceptions during the summarization process.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_cpp.html">parser_cpp</a><br/><small>This Python module provides a simple parser for C++ files used by DocGen-LM. It extracts namespaces, classes, functions, and public variables from the source code. The parser returns a structured dictionary containing `module_docstring`, `classes`, and `functions`. Each class and function includes their respective documentation comments, source snippets, and any leading comments. The module uses line-based parsing to identify and extract these elements, making it compatible with Python&#x27;s `parse_python_file` structure.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_java.html">parser_java</a><br/><small>A simple parser for Java files used by DocGen-LM. Extracts package, classes, public methods, and variables using naive line-based parsing. The output mirrors `parse_python_file` with keys `module_docstring`, `classes`, and `functions`. Each entry includes its source code and leading documentation comments (Javadoc or `//`).</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>This module provides a function to parse MATLAB `.m` files and extract basic structure. It reads the file content, identifies leading comment lines as the file header, and extracts `function` declarations along with their arguments. The parsed data is returned in a dictionary containing the file header comments and a list of functions, each represented by its name and arguments.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>This module provides a parser for Python files using the `ast` module to extract structured information according to the Software Requirements Specification (SRS). It includes functions to format arguments and signatures of functions, parse classes and functions within a Python file, and retrieve structured information about the parsed content. The main entry point is `parse_python_file`, which takes a file path as input and returns a dictionary containing the module docstring, classes, and functions.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>This module provides a tool to review HTML documentation generated by DocGen-LM. It checks for assistant-like phrases, contradictions, and hallucinations in the HTML content. The tool can also automatically fix some issues by sanitizing paragraphs using a `sanitize_summary` function from the `llm_client` library.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>This module defines a function `scan_directory` that recursively discovers source files of specific types (`.py`, `.m`, `.cpp`, `.h`, `.java`) within a given directory, while ignoring specified paths. It uses optional progress bar display if enabled and handles an optional dependency on the `tqdm` library for progress tracking. The function returns a sorted list of absolute paths to the discovered files.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a><br/><small>This module sets up a Python package using `setuptools`. It defines the entry point for running the script, which executes the `setup` function from `setuptools`. The `setup` function is called with parameters specifying that three Python modules (`explaincode`, `parser_cpp`, and `parser_java`) should be included in the package.</small></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>This module provides functions for summarizing text using a language model client and caching responses. It includes:

1. `_summarize`: A helper function to summarize text directly or retrieve from cache.
2. `summarize_chunked`: A main function that summarizes large texts by chunking them if necessary, ensuring the context fits within token limits. It handles exceptions during chunking and summarization, using a recursive merging approach to combine summaries into a single paragraph.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>This module defines two functions for testing a response cache implementation. The `test_cache_round_trip` function tests setting and retrieving a value from the cache, ensuring that the value persists across cache instances. The `test_cache_get_missing` function tests attempting to retrieve a non-existent key from the cache, expecting a `None` result.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>The module defines several test functions to verify the functionality of `get_tokenizer` and `chunk_text`. It includes tests for:

1. Ensuring that `get_tokenizer` returns a tokenizer object.
2. Verifying that encoding and decoding text using the tokenizer preserves the original string.
3. Confirming that `chunk_text` can split a long text into chunks without reconstructing the content.
4. Checking that `chunk_text` splits markdown headings correctly when chunk size is limited.
5. Ensuring that `chunk_text` handles code blocks within the text appropriately, maintaining their integrity across chunks.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>The module contains several test functions for a documentation generator. It uses the `unittest.mock` library to patch dependencies and simulate behavior of an LLMClient during testing. The tests cover various scenarios such as skipping invalid Python files, generating summaries for classes and functions, handling non-UTF8 files, sanitizing project summaries, using README content, cleaning output directories, chunking long text, and processing different types of source code files (Python, C++, Java).</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>This module defines a test function `test_subclass_docs_and_method_summary` that uses the `unittest.mock.patch` decorator to mock an `LLMClient`. The function creates a temporary project directory with a Python file containing a subclass and a method. It then calls the `main` function from the `docgenerator` module, passing in the path to the project directory and specifying an output directory for documentation. The test asserts that the return value of the `main` function is 0, indicating success. It also checks that the generated HTML documentation contains summaries for the class and method, as expected.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>The module provides a comprehensive suite of functions and tests for creating documentation summaries, extracting text from files, rendering HTML content, and handling various file formats. It includes a mock LLM client for summarization purposes and tests for scenarios such as Markdown, HTML, and DOCX files, as well as generating user manuals in both HTML and PDF formats. The module also contains functions for collecting documentation files, mapping evidence to sections, detecting placeholders, parsing manual content, validating references, inferring sections from context, and extracting snippets from code files. Additionally, it features test functions for a code documentation tool, covering functionalities like categorizing code snippets, ranking code files, filling placeholders in user manuals, handling different file types (e.g., Python, C++, Java), skipping or forcing code scans based on flags, and inserting generated documentation into existing index files. The tests use mock objects and assertions to ensure the correctness of implemented functions. Furthermore, it includes test functions for a summarization process that verify aspects such as chunking, caching, and logging. These tests utilize a mock client to simulate API calls and confirm that the summarization process operates correctly, with checks on output accuracy and appropriate system prompts. Some tests also validate caching functionality by re-running the summarization with identical input to ensure no new API calls are made.</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>This module defines functions to generate HTML documentation for Python modules, including indices and individual module pages. It uses the `html_writer` module for HTML generation. The module includes tests to ensure that the generated HTML is correct, covering various aspects such as rendering of links, summaries, variables, classes, methods, and nested structures like subfunctions and subclasses. Additionally, it provides a function `_highlight` to syntax-highlight code snippets in C++ and Java.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>The module defines two test functions for a documentation generator. The first function, `test_docgenerator_generates_html`, tests the generation of HTML files from various types of source code files (Python, MATLAB, C++, Java) using a mock LLMClient. It asserts that the output directory contains the expected HTML files and that they contain the correct summary text.

The second function, `test_static_copied_from_any_cwd`, tests that static resources are copied to the output directory regardless of the current working directory. It asserts that the `style.css` file is present in the output directory&#x27;s `static` folder.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>The module defines unit tests for an `LLMClient` class. It includes tests for the `ping` method, which checks if the client can successfully connect to a server, and the `summarize` method, which sends text to a language model for summarization. The `sanitize_summary` function filters out disclaimers from the summary text. Each test uses mock objects to simulate HTTP requests and responses, and assertions to verify that the methods behave as expected under different conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>The module defines two functions: `_count` and `test_chunk_docs_respects_token_limit`, `test_find_placeholders`. The `_count` function calculates the number of tokens in a given text using a tokenizer from the `manual_utils` module. The `test_chunk_docs_respects_token_limit` function tests the `chunk_docs` function from `manual_utils` to ensure it respects a token limit by splitting documents into chunks that do not exceed the limit. The `test_find_placeholders` function tests the `find_placeholders` function from `manual_utils` to verify its ability to identify and return placeholders in a given text.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_cpp.html">test_parser_cpp</a><br/><small>This module defines a test function `test_parse_cpp` that uses the `parse_cpp_file` function from `parser_cpp.py` to parse a C++ source file. The test checks if the parsed data includes the expected module comment, namespace, functions, and classes with their respective docstrings and source code snippets.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_java.html">test_parser_java</a><br/><small>This module defines a test function `test_parse_java` that uses the `parse_java_file` function from the `parser_java` module to parse a Java source file. The test checks if the parsed result contains the expected package, class, field, and method information.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>This module defines two test functions to verify the functionality of a MATLAB file parser. The `test_parse_simple_matlab` function checks if the parser correctly handles a simple MATLAB file with a single function. It asserts that the header is parsed correctly and that the function details are accurately extracted.

The `test_parse_multiple_functions` function tests the parser&#x27;s ability to handle multiple functions within a single MATLAB file. It verifies that both functions are correctly identified, their names and arguments are accurately captured, and that there are no issues with parsing files containing more than one function.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>The module defines several test functions to verify the functionality of a `parse_python_file` function. Each test function creates a Python source file with specific content, parses it using `parse_python_file`, and then asserts that the parsed data matches expected values.

- `test_parse_simple_module`: Tests parsing a simple Python module with a docstring, class, and method.
- `test_parse_complex_signature`: Tests parsing a function with complex signature parameters.
- `test_parse_nested_structures`: Tests parsing nested functions and classes.
- `test_deeply_nested_classes`: Tests parsing deeply nested classes.
- `test_class_inside_method`: Tests parsing a class defined inside another class.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>This module defines several functions and tests for a code review tool. It includes:

1. `_make_module`: Creates a temporary module with specified summary and methods, then writes an HTML page for it.
2. `test_assistant_phrasing_detected`: Tests if the assistant phrasing is detected when &quot;You can use this class&quot; is in the module summary.
3. `test_contradiction_detected`: Checks if a contradiction is detected when methods are defined but not described in the summary.
4. `test_hallucination_detected`: Verifies that a hallucination is flagged when the module claims to implement features it doesn&#x27;t.
5. `test_autofix_removes_phrasing`: Tests if autofix removes phrasing like &quot;You can&quot; from the HTML output.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>This module defines several tests for a `scan_directory` function. It uses the `pytest` framework to validate that the function correctly identifies and returns files of specified types, excluding directories listed in an ignore list and skipping common version control directories like `.git`. The tests create temporary file structures using `pathlib`, call `scan_directory`, and assert the results match expected outputs.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
