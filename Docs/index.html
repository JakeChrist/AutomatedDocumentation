<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul><li><a href="cache.html">cache</a></li><li><a href="chunk_utils.html">chunk_utils</a></li><li><a href="docgenerator.html">docgenerator</a></li><li><a href="explaincode.html">explaincode</a></li><li><a href="gui_wrapper.html">gui_wrapper</a></li><li><a href="html_writer.html">html_writer</a></li><li><a href="llm_client.html">llm_client</a></li><li><a href="manual_utils.html">manual_utils</a></li><li><a href="parser_cpp.html">parser_cpp</a></li><li><a href="parser_java.html">parser_java</a></li><li><a href="parser_matlab.html">parser_matlab</a></li><li><a href="parser_python.html">parser_python</a></li><li><a href="retrofit_sidebar.html">retrofit_sidebar</a></li><li><a href="reviewer.html">reviewer</a></li><li><a href="sanitize_docs.html">sanitize_docs</a></li><li><a href="scanner.html">scanner</a></li><li><a href="setup.html">setup</a></li><li><a href="summarize_utils.html">summarize_utils</a></li><li><details><summary>tests</summary><ul><li><a href="test_cache.html">test_cache</a></li><li><a href="test_chunk_utils.html">test_chunk_utils</a></li><li><a href="test_docgenerator.html">test_docgenerator</a></li><li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li><li><a href="test_explaincode.html">test_explaincode</a></li><li><a href="test_html_writer.html">test_html_writer</a></li><li><a href="test_integration.html">test_integration</a></li><li><a href="test_llm_client.html">test_llm_client</a></li><li><a href="test_manual_utils.html">test_manual_utils</a></li><li><a href="test_parser_cpp.html">test_parser_cpp</a></li><li><a href="test_parser_java.html">test_parser_java</a></li><li><a href="test_parser_matlab.html">test_parser_matlab</a></li><li><a href="test_parser_python.html">test_parser_python</a></li><li><a href="test_resume_progress.html">test_resume_progress</a></li><li><a href="test_retrofit_sidebar.html">test_retrofit_sidebar</a></li><li><a href="test_reviewer.html">test_reviewer</a></li><li><a href="test_sanitize_docs.html">test_sanitize_docs</a></li><li><a href="test_scanner.html">test_scanner</a></li></ul></details></li></ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM is a tool that generates static HTML documentation for Python, MATLAB, C++, and Java projects by analyzing source files and summarizing them with a local language model. It supports nested structures like functions and subclasses, rendering them as expandable sections in the output. The tool includes features such as automatic progress saving, resumable runs, and integration with LMStudio for local LLM access.

The documentation generator provides both command-line and graphical user interface options, allowing users to configure settings like output directories, ignored paths, and LLM parameters. It also offers utilities for sanitizing existing documentation, retrofitting sidebars, and generating project summaries with optional code fallback mechanisms.

Key functionalities include token-based chunking for large inputs, automatic detection of supported languages, and flexible summarization modes that can handle various content sizes and structures. The system maintains cached progress to support interrupted runs and provides options for controlling code scanning behavior during documentation generation.
This project generates documentation for codebases by analyzing source files and producing structured summaries. It supports multiple programming languages including Python, C++, Java, and MATLAB, using language-specific parsers to extract function and class definitions along with their comments. The system employs LLM-based summarization to create high-level overviews and detailed docstrings, with caching mechanisms to store intermediate results and avoid redundant processing. A graphical user interface allows users to configure paths and execute documentation generation tasks. The output is rendered into HTML pages with navigation structures, and includes utilities for reviewing generated content, sanitizing AI-generated text, and integrating documentation into existing projects.</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>The module implements a disk-based cache for storing and retrieving LLM responses. It provides functionality to generate deterministic keys based on file paths and content, retrieve cached values, store new values, and manage progress tracking for processed modules. The cache persists data to a JSON file and supports operations to clear progress information.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>The module provides utilities for splitting text into chunks based on natural boundaries like blank lines, Markdown headings, and code fences. It includes functions to strip special FIM tokens, obtain a tokenizer for estimating token counts, and split text into chunks that are approximately a specified number of tokens in size. When a single block exceeds the token limit, it falls back to splitting by character length. The module uses an optional `tiktoken` library for accurate tokenization, with a fallback to a simple space-based splitter if `tiktoken` is unavailable.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>This module implements a command-line interface for generating HTML documentation from source code using language model APIs. It processes Python, MATLAB, C++, and Java files by parsing their structural elements, requesting summaries from an LLM client, and writing results to HTML output. The implementation includes functions for cleaning output directories, summarizing code modules with token-based chunking, merging partial summaries, building context-aware prompts for function documentation, rewriting docstrings, and recursively processing functions and class members. It supports caching of LLM responses and handles large code structures by breaking them into manageable chunks while preserving original source structure during processing. The module provides recursive processing of classes, methods, and variables to generate comprehensive summaries and rewrite docstrings, with main functionality that parses source files, builds project summaries, and generates HTML documentation containing navigation and markdown context. It manages caching for both progress tracking and LLM responses, supports resuming or clearing progress, and uses tokenization and chunking techniques to handle large inputs within context limits across multiple programming languages.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>This module provides functionality for generating project documentation summaries by processing documentation and code files. It includes configuration handling, file collection from specified paths, and text extraction from various document formats. The module supports section mapping based on keywords, ranking of code files using heuristics, and insertion of navigation links into HTML index files. It defines functions for extracting code snippets from files, organizing them by manual sections, and generating documentation using LLMs, including logic to scan code files, parse Python syntax, and collect relevant documentation parts such as docstrings, CLI parsers, and main blocks. The `scan_code` function ranks files based on patterns and categorizes snippets into sections, while `llm_generate_manual` creates manual sections from documentation snippets and `llm_fill_placeholders` updates the manual by replacing placeholder tokens with information extracted from code snippets. An auxiliary function `_edit_chunks_in_editor` allows users to manually edit documentation chunks in their preferred editor. The module also includes functions for rendering HTML from structured sections, parsing manual content into sections, validating file references within those sections, inferring section structure from plain text, and writing HTML content to PDF format. The `render_html` function generates an HTML document with navigation and styled content, incorporating evidence snippets when section content is missing.</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>The module implements a graphical user interface for running documentation generation and code explanation tools. It defines custom widgets including a path input field that accepts file drops, and a collapsible section for options. A background thread executes shell commands and emits output for display in a log window. The main window contains controls for specifying project and output directories, toggles for DocGen options such as including private functions and language selection, and options for ExplainCode including output format and data file inclusion. Buttons trigger execution of DocGen, ExplainCode, or both tools sequentially. The interface uses a dark theme and handles user interactions for directory and file selection, command execution, and log display with progress updates.</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>Module provides HTML rendering utilities for generating documentation pages from structured data. It includes functions to render navigation trees, highlight code snippets using Pygments, and generate complete HTML pages with templates. The module supports rendering project overviews, module pages with classes, functions, and variables, and handles nested structures through recursive rendering functions. It processes data dictionaries containing documentation elements and outputs styled HTML files with proper escaping and formatting.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>The module defines an interface for interacting with a local LLM backend, specifically designed for generating code summaries. It includes prompt templates for different code elements such as modules, classes, functions, and README files, along with a system prompt that instructs the model to produce factual, concise descriptions without self-reference or additional commentary. The `LLMClient` class handles communication with the LMStudio API, sending requests and processing responses while managing token counts and retry logic for failed requests. A `sanitize_summary` function cleans generated summaries by removing meta-commentary and prompt-related content that could cause issues downstream. The module uses HTTP requests to interact with the LLM backend and includes utilities for tokenization and FIM token stripping to ensure compatibility with the model&#x27;s input requirements.</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>The module implements functions for splitting documentation into chunks, summarizing those chunks using an LLM client, and merging the results into a structured user manual. It includes logic for handling token and character limits, caching responses, and managing parallel processing of chunks. The process supports automatic chunking based on limits, manual chunking, or no chunking, with fallback behaviors for errors or exceeding limits. Placeholder tokens are identified and handled during the merging phase. The module uses system prompts to guide the LLM in generating content focused on user-level instructions rather than implementation details.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_cpp.html">parser_cpp</a><br/><small>Module implements a line-based parser for C++ source files to extract namespaces, classes, functions, and public variables. It processes comments and code blocks to build structured data containing documentation strings, source code snippets, and element signatures. The parser handles multi-line comments, class member access specifiers, and function signatures while maintaining compatibility with Python parsing structures. Functions include collecting preceding comments, extracting code blocks enclosed in braces, and parsing class bodies for public methods and variables. The main entry point reads a file, identifies top-level elements, and returns a dictionary with module documentation, class definitions, and function declarations.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_java.html">parser_java</a><br/><small>Module implements a Java file parser for DocGen-LM that extracts package information, class definitions, public methods, and variables. It uses line-based parsing to identify code elements and their associated documentation comments, including Javadoc and single-line comments. The parser processes source code to build structured data containing element names, signatures, documentation strings, and source code blocks. Functions handle comment extraction, block parsing, and class body analysis. Output format mirrors Python parsing structure with keys for module docstring, classes, and functions, though functions list remains empty for Java files.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>The module provides a parser for MATLAB `.m` files that extracts file header comments and function declarations. It reads the content of a specified file, identifies leading comment lines as the file header, and parses subsequent lines to find function definitions. Each function entry includes the function name and its arguments, which are extracted and formatted into a list. The parser uses regular expressions to match function declarations and handles both comma- and semicolon-separated argument lists. The output is a dictionary containing the parsed header and a list of functions with their names and argument lists.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>Module defines a parser for Python files that extracts structured information using the `ast` module. It processes classes and functions, capturing their signatures, docstrings, and source code segments. The parser handles positional-only arguments, default values, variable arguments, keyword-only arguments, and nested definitions. It supports both synchronous and asynchronous function definitions. The output includes module-level docstring, lists of classes and functions, with each containing details about their structure and content.</small></li>
<li style="margin-bottom: 1em;"><a href="retrofit_sidebar.html">retrofit_sidebar</a><br/><small>The module implements a tool to replace documentation sidebars with hierarchical lists of modules. It scans a source directory for files, constructs a tree structure from their paths, and generates HTML unordered lists to populate sidebar divs in documentation files. The script uses BeautifulSoup for HTML manipulation and supports command-line arguments for specifying the source and documentation directories. The process involves resolving file paths relative to a base directory, building a nested dictionary representation of the module structure, and converting this structure into HTML list elements with appropriate links to module documentation pages.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>Module defines a documentation reviewer for HTML output generated by DocGen-LM. It identifies assistant-like phrasing, contradictions between summary and detected elements, and hallucinated content. The tool processes HTML files in a directory, reporting issues found. Optional autofix mode rewrites files to sanitize paragraph content using an external client function. Command-line interface accepts a directory path and an autofix flag.</small></li>
<li style="margin-bottom: 1em;"><a href="sanitize_docs.html">sanitize_docs</a><br/><small>The module provides functionality to sanitize HTML documentation files within a specified directory. It uses a regular expression pattern to identify specific HTML tags (p, li, h1-h6) and applies a cleaning function to their content. The cleaning process removes nested HTML tags from the content and then sanitizes the resulting text using an external `sanitize_summary` function from `llm_client`. The sanitized content replaces the original content in-place within the HTML files. A command-line interface is included to specify the directory containing the HTML files for processing.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>Module implements source file discovery for DocGen-LM with recursive directory scanning and ignore rules. It identifies Python, MATLAB, C++, C, and Java files under a base path while excluding specified directories and files. The function supports optional progress bar display during scanning. Scanning respects ignore patterns relative to the base path and excludes .git directories. Results are returned as sorted list of absolute file paths.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>Module implements a chunked text summarization function that uses an LLM client and response cache. It handles text that exceeds token limits by splitting into chunks, summarizing each chunk, and recursively merging summaries. The function manages token overhead from system prompts and templates, falls back to single-summary mode for short texts, and includes error handling for chunking, summarization, and merging steps. Cached responses are sanitized before being returned.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>Module defines tests for `ResponseCache` class functionality including cache round-trip operations, handling missing keys, and progress tracking with clearing capabilities.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>Module defines tests for tokenization and text chunking functionality. Tests verify tokenizer round-trip encoding/decoding, removal of FIM tokens, proper reconstruction of text from chunks, splitting of markdown headings, and preservation of code blocks during chunking. Uses `chunk_utils` module for chunking and tokenizer retrieval. Contains four test functions covering different aspects of text processing behavior.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>Module defines test cases for a documentation generator tool. Tests cover handling of invalid Python syntax, generation of class and function summaries, skipping non-UTF8 files, sanitization of project summaries, use of README content, cleaning output directories, chunked text summarization with token budgeting, recursive merging of long texts, structured chunking for functions and classes, subclass method processing, and support for C++ and Java file types. Tests utilize mocking of LLMClient and related functions to isolate functionality and verify correct behavior under various conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>Test function that verifies documentation generation for nested class methods. Creates a temporary project structure with a nested class and method, mocks the LLM client to return predefined summaries, executes the documentation generator main function, and validates that the output HTML contains expected summary markers for both the nested class and its method.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>The code defines a comprehensive testing suite for documentation processing and summarization workflows, encompassing fixture creation and LLM client mocking functionalities. It includes tests for extracting text from various file formats (Markdown, HTML, DOCX), rendering HTML summaries with tables of contents and evidence blocks, generating user manuals in HTML and PDF formats, handling missing dependencies, custom output directories, collecting documentation files, mapping evidence to sections with priority and filtering, limiting snippet lengths, detecting placeholders, parsing manual sections with inferred content, validating references, inferring section content, skipping large files during snippet extraction, and scanning code while excluding non-source directories. Additional test cases cover code documentation generation functionality including snippet categorization, file ranking with language support, LLM placeholder filling with logging, code scan skipping behaviors, fallback mechanisms with limits, code flag interactions, custom output naming, and index insertion features. The suite also verifies automatic chunking and summarization logic in `manual_utils._summarize_manual`, confirming multiple LLM calls during chunking, proper system prompts for chunk and merge operations, logging of chunking steps, application of post-processing hooks, parallel execution of chunk summaries, hierarchical merging with logging, reuse of cached chunk results, absence of LLM calls when chunking is disabled, and sanitization of</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>Module defines tests for HTML documentation generation functions. Tests cover index page creation with nested module structures, module page rendering including classes, functions, variables, and their documentation, subfunction and subclass handling, and syntax highlighting for C++ and Java code snippets. Test functions validate HTML output structure, content encoding, navigation links, code formatting, and proper display of documentation elements.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>Module defines tests for the `docgenerator` tool, verifying HTML generation from code files in multiple languages including Python, MATLAB, C++, and Java. Tests check that output HTML files are created with expected content and that static assets like CSS are copied correctly regardless of current working directory. The tests mock an LLM client to simulate documentation generation without external dependencies.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>Module defines tests for an LLM client that interacts with a remote API to summarize code. Tests cover successful and failed ping operations, retry behavior during summarization, error handling for HTTP errors, and filtering of summary text. It verifies correct prompt template usage based on entity type and ensures proper sanitization of output. The module uses mocking to isolate the client logic from external dependencies.</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>Module defines tests for document chunking and placeholder finding functionality. Includes a helper function that counts tokens in text using a tokenizer, and two test functions that verify chunking respects token limits and that placeholder detection correctly identifies specific patterns in text.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_cpp.html">test_parser_cpp</a><br/><small>Test function that validates parsing of C++ source code containing a namespace, function, and class with documentation comments. The test creates a temporary C++ file with documented code elements, parses it using `parse_cpp_file`, and verifies that the parsed output correctly extracts module documentation, namespace name, function details including name, docstring, and source code, and class details including name, docstring, member variables, and methods with their respective documentation and source code.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_java.html">test_parser_java</a><br/><small>Test function that validates parsing of a Java source file containing a package declaration, class definition with fields and methods, and associated documentation comments. The test checks extraction of module docstring, package name, class details including name and docstring, field information such as name, type, and source code, and method details including name and source code. Uses a temporary file to store test Java content and verifies parsed output against expected values.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>Module defines tests for parsing MATLAB files. Includes test cases for parsing a simple MATLAB file with one function and header comments, and another test case for parsing a file containing multiple functions. Both tests use temporary files and validate parsed output structure including header text and function metadata such as names and argument lists. Uses `parse_matlab_file` function from `parser_matlab` module.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>Module defines test cases for parsing Python files using a `parse_python_file` function. Tests cover simple modules with functions and classes, including docstrings and signatures. Additional tests handle complex function signatures with positional-only, keyword-only, and variable arguments. Nested structures such as inner functions, nested classes, and classes defined inside methods are also tested. Each test validates specific aspects of the parsed output like names, signatures, docstrings, and source code inclusion.</small></li>
<li style="margin-bottom: 1em;"><a href="test_resume_progress.html">test_resume_progress</a><br/><small>Test function that verifies resume functionality of the documentation generator. Sets up a project with two Python modules and simulates a failure during caching of progress. After the failure, it checks that only the first module&#x27;s progress is recorded in the cache. Then, it runs the generator again with resume flag, verifying that only the second module is processed and both HTML files are generated. The test confirms that the cache state is properly managed across failures and resumptions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_retrofit_sidebar.html">test_retrofit_sidebar</a><br/><small>The module defines tests for the `retrofit_sidebar` function and its associated `main` function. The tests verify that `retrofit_sidebar` correctly updates HTML documentation files by inserting a sidebar with links to Python source files and their submodules. It checks that the sidebar structure is built properly, with correct file paths and names. The tests also confirm that `main` exits with an error code and reports appropriate errors when the source or documentation directories are missing.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>Module defines tests for detecting specific phrases and issues in documentation files. Tests check for assistant phrasing, contradictions, and hallucinations using a reviewer tool. The module includes functions to generate HTML module pages and run the reviewer on specified paths. It verifies detection of problematic text patterns and ensures autofix functionality removes assistant phrasing from generated HTML.</small></li>
<li style="margin-bottom: 1em;"><a href="test_sanitize_docs.html">test_sanitize_docs</a><br/><small>Tests for the sanitize_docs utility that verify removal of AI disclaimers from HTML files in a directory. The tests check handling of paragraph elements, headings, and list items, ensuring disclaimer text is removed while preserving relevant content. Tests use temporary directories and validate the output after processing.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>Module defines tests for a `scan_directory` function that identifies specific file types while ignoring designated folders. Tests verify behavior with ignored directories, mixed file extensions, Git folder exclusion, and support for C++, C++, and Java file types. Helper function `create_files` generates test files in specified paths. Tests use `tmp_path` fixture for temporary directories and assert expected file paths are returned.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
