<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Project Documentation</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul><li><a href="cache.html">cache</a></li><li><a href="chunk_utils.html">chunk_utils</a></li><li><a href="docgenerator.html">docgenerator</a></li><li><a href="explaincode.html">explaincode</a></li><li><a href="gui_wrapper.html">gui_wrapper</a></li><li><a href="html_writer.html">html_writer</a></li><li><a href="llm_client.html">llm_client</a></li><li><a href="manual_utils.html">manual_utils</a></li><li><a href="parser_cpp.html">parser_cpp</a></li><li><a href="parser_java.html">parser_java</a></li><li><a href="parser_matlab.html">parser_matlab</a></li><li><a href="parser_python.html">parser_python</a></li><li><a href="retrofit_sidebar.html">retrofit_sidebar</a></li><li><a href="reviewer.html">reviewer</a></li><li><a href="sanitize_docs.html">sanitize_docs</a></li><li><a href="scanner.html">scanner</a></li><li><a href="setup.html">setup</a></li><li><a href="summarize_utils.html">summarize_utils</a></li><li><details><summary>tests</summary><ul><li><a href="test_cache.html">test_cache</a></li><li><a href="test_chunk_utils.html">test_chunk_utils</a></li><li><a href="test_docgenerator.html">test_docgenerator</a></li><li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li><li><a href="test_explaincode.html">test_explaincode</a></li><li><a href="test_html_writer.html">test_html_writer</a></li><li><a href="test_integration.html">test_integration</a></li><li><a href="test_llm_client.html">test_llm_client</a></li><li><a href="test_manual_utils.html">test_manual_utils</a></li><li><a href="test_parser_cpp.html">test_parser_cpp</a></li><li><a href="test_parser_java.html">test_parser_java</a></li><li><a href="test_parser_matlab.html">test_parser_matlab</a></li><li><a href="test_parser_python.html">test_parser_python</a></li><li><a href="test_resume_progress.html">test_resume_progress</a></li><li><a href="test_retrofit_sidebar.html">test_retrofit_sidebar</a></li><li><a href="test_reviewer.html">test_reviewer</a></li><li><a href="test_sanitize_docs.html">test_sanitize_docs</a></li><li><a href="test_scanner.html">test_scanner</a></li></ul></details></li></ul>
    </div>
    <div class="content">
        <h1>Project Documentation</h1>
        <p>DocGen-LM is a tool that generates static HTML documentation for Python, MATLAB, C++, and Java projects by analyzing source files and summarizing them with a local LLM, supporting nested structures like functions and subclasses. It includes features such as automatic progress saving, resumable documentation generation, and integration with LMStudio as the backend LLM server. The tool also provides a graphical user interface for easier interaction and additional utilities for sanitizing existing documentation and generating project summaries with customizable output formats.
This project provides tools for generating and managing documentation from source code. It includes modules for parsing various programming languages, chunking text for processing, summarizing code elements, and rendering HTML output. The system supports caching of responses, progress tracking, and integration with LLMs for automated documentation generation. It also offers functionality for reviewing generated content, sanitizing outputs, and building navigable documentation websites from source files.</p>
<hr/>
<h2>Modules</h2>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 1em;"><a href="cache.html">cache</a><br/><small>The module implements a disk-based cache for storing and retrieving Large Language Model (LLM) responses. It provides functionality to save and load cached data from a JSON file, using deterministic keys derived from file paths and content hashes. The cache supports storing individual response entries and tracking progress of processed modules. The implementation ensures data persistence by writing changes to disk upon modification.</small></li>
<li style="margin-bottom: 1em;"><a href="chunk_utils.html">chunk_utils</a><br/><small>The module provides utilities for splitting text into chunks based on natural boundaries like blank lines, Markdown headings, and code fences. It includes functions to estimate token counts using the `tiktoken` library, with a fallback to a simple space-based tokenizer if `tiktoken` is unavailable. The main function `chunk_text` splits input text into segments approximately matching a specified token size, preserving structural elements of the text. When a single block exceeds the token limit, it falls back to character-based splitting to ensure all content is included. Helper functions manage the identification of text blocks and handle the fallback splitting logic for oversized sections.</small></li>
<li style="margin-bottom: 1em;"><a href="docgenerator.html">docgenerator</a><br/><small>This module implements a command-line interface for generating HTML documentation from source code using language models, supporting Python, MATLAB, C++, and Java file types. It processes source files by parsing their structure, summarizing content through recursive LLM interactions, and producing structured HTML output with an index page and individual module pages. The implementation includes functions for cleaning output directories, caching LLM responses to avoid redundant processing, chunking module structures for efficient processing, and recursively summarizing classes and their members. It builds context-aware prompts for function summarization, rewrites docstrings using LLMs, and handles token budgeting for LLM interactions while including error handling for network failures and processing issues. The system supports resuming previous runs and clearing progress after successful execution, with command-line argument parsing for configuration management.</small></li>
<li style="margin-bottom: 1em;"><a href="explaincode.html">explaincode</a><br/><small>The module provides functionality for generating project documentation summaries by processing documentation and code files through a series of defined steps. It includes configuration handling, file collection from specified paths, and text extraction from various document formats. The system supports section mapping based on keywords, code file ranking using heuristics, and utilities for inserting navigation links into HTML index files. Key functions scan code files to extract relevant content such as docstrings, function signatures, CLI parsers, and main blocks, organizing them by manual sections. These snippets are used to generate documentation via LLMs, with support for filling placeholder tokens in text using extracted code information. The module also offers capabilities for rendering HTML from structured sections, parsing manual content into sections, validating file references, inferring section structure from plain text, and generating PDFs from HTML. A main orchestration function accepts command-line arguments to configure processing parameters, collect and read documentation files, process them using an LLM client with caching, and attempt multiple passes to generate a manual. In case of LLM failure, it falls back to inferring sections from combined text, ultimately rendering output as HTML or PDF and optionally inserting it into an index file while saving evidence maps separately.</small></li>
<li style="margin-bottom: 1em;"><a href="gui_wrapper.html">gui_wrapper</a><br/><small>The module implements a graphical user interface for running documentation generation and explanation tools. It defines custom widgets including a path line edit that accepts file drops and a collapsible box for organizing options. A command runner thread handles execution of external processes, capturing output in real time. The main window contains input fields for project and output directories, checkboxes for DocGen options, and controls for ExplainCode settings. Buttons trigger execution of DocGen, ExplainCode, or both tools sequentially. The interface supports dark-themed styling and displays command output in a log area with scrollable text handling. File dialogs enable selection of directories and data files. The application uses PyQt5 for the GUI framework and subprocess for executing external Python scripts.</small></li>
<li style="margin-bottom: 1em;"><a href="html_writer.html">html_writer</a><br/><small>Module provides HTML rendering utilities for generating documentation pages from structured data. It includes functions to render navigation trees, highlight code snippets using Pygments, and generate complete HTML pages with templates. The module supports rendering project overviews, module pages with classes, functions, and variables, and handles nested structures through recursive rendering functions. It uses a template-based approach to assemble final HTML output with proper escaping and formatting.</small></li>
<li style="margin-bottom: 1em;"><a href="llm_client.html">llm_client</a><br/><small>The module defines an interface for interacting with a local LLM backend, specifically designed for generating code summaries. It includes prompt templates for different code elements such as modules, classes, functions, and README files, along with a system prompt that instructs the model to produce factual, concise descriptions without self-reference or extraneous information. The `LLMClient` class handles communication with the LMStudio API, sending requests and processing responses, including token counting and sanitization of output to remove unwanted content. It supports retry logic for failed requests and includes utilities for cleaning up special tokens and filtering out meta-commentary from summaries.</small></li>
<li style="margin-bottom: 1em;"><a href="manual_utils.html">manual_utils</a><br/><small>The module implements functions for splitting documentation into chunks, summarizing content using an LLM client, and merging summaries into a structured user manual. It includes logic for handling token and character limits, caching responses, and managing parallel processing of document parts. The module supports different chunking strategies—automatic, manual, or none—and applies system prompts tailored to chunking or merging tasks. Placeholder tokens are identified and handled during the summarization process. The implementation uses a tokenizer for estimating token counts and includes error handling for network failures and chunking issues.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_cpp.html">parser_cpp</a><br/><small>Module defines a C++ file parser that extracts namespaces, classes, functions, and public variables. It processes source code line-by-line to identify structural elements and their associated documentation comments. The parser collects leading comment blocks preceding each element and captures the source code snippets for each parsed item. It handles both single-line and multi-line comment formats, including block comments delimited by `/* */`. The output structure includes module-level documentation, lists of classes with their methods and variables, and a list of functions, each containing name, signature, documentation, and source code. The parser supports class body parsing to distinguish public methods and variables based on access specifiers. It returns data in a format compatible with Python file parsing functions.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_java.html">parser_java</a><br/><small>Module implements a parser for Java source files to extract package information, class definitions, public methods, and variables. It processes Java files line-by-line, identifying package declarations, class blocks, and their contents including documentation comments. The parser handles both single-line variable declarations and method signatures within classes. It supports extraction of Javadoc-style comments and line comments preceding code elements. The output structure includes module-level documentation, a list of classes with their methods and variables, and an empty functions list. Each extracted element contains its source code and associated documentation. The parser uses helper functions to manage comment extraction and block parsing for class bodies.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_matlab.html">parser_matlab</a><br/><small>The module provides a parser for MATLAB `.m` files that extracts file header comments and function declarations. It reads the file content line by line, identifies leading comment blocks as the file header, and collects function definitions from the remaining content. Each function entry includes its name and a list of arguments parsed from the function signature. The parser uses regular expressions to match function declarations and handles both comma-separated and semicolon-separated argument lists. The output is a dictionary containing the extracted header text and a list of function details, where each detail includes the function name and its arguments.</small></li>
<li style="margin-bottom: 1em;"><a href="parser_python.html">parser_python</a><br/><small>Module defines a parser for Python files that extracts structured information using the `ast` module. It processes classes and functions, capturing their signatures, docstrings, and source code segments. The parser supports nested structures, including methods within classes and subfunctions within functions. It formats function arguments and handles default values, annotations, and keyword-only parameters. The main entry point is `parse_python_file`, which reads a file and returns a dictionary containing module-level information, classes, and functions. Helper functions format argument lists and function signatures, while recursive parsing handles nested definitions.</small></li>
<li style="margin-bottom: 1em;"><a href="retrofit_sidebar.html">retrofit_sidebar</a><br/><small>The module implements a tool to replace documentation sidebars with hierarchical lists of modules. It scans a source directory for files, constructs a tree structure from their paths, and generates HTML unordered lists to populate sidebar elements in documentation files. The tool uses BeautifulSoup for HTML parsing and modification, and includes command-line argument parsing to specify source and documentation directories. The process involves resolving file paths, building a nested dictionary representation of the module structure, and converting this structure into HTML list elements with appropriate links. The script operates on all HTML files within the specified documentation directory, modifying their sidebar content in place.</small></li>
<li style="margin-bottom: 1em;"><a href="reviewer.html">reviewer</a><br/><small>Module defines a documentation reviewer for HTML output generated by DocGen-LM. It identifies assistant-like phrasing, contradictions between summary and detected elements, and hallucinated content. The tool processes HTML files in a directory, reporting issues found. An optional autofix mode rewrites files to sanitize paragraph content using an external client function. Command-line interface accepts a directory path and an autofix flag.</small></li>
<li style="margin-bottom: 1em;"><a href="sanitize_docs.html">sanitize_docs</a><br/><small>The module provides functionality to sanitize HTML documentation files within a specified directory. It uses a regular expression pattern to identify specific HTML tags (p, li, h1-h6) and applies content cleaning through the `sanitize_summary` function from `llm_client`. The sanitized content replaces the original text within these tags. A command-line interface accepts a directory path and processes all HTML files found recursively within that directory, modifying them in place. The script exits with status code 0 upon successful completion.</small></li>
<li style="margin-bottom: 1em;"><a href="scanner.html">scanner</a><br/><small>Module implements source file discovery for DocGen-LM with recursive directory scanning and ignore rules. It identifies Python, MATLAB, C++, C, and Java files under a base directory while excluding specified paths and .git folders. The function accepts a base path, list of ignored relative paths, and optional progress bar display. Results are returned as sorted absolute paths to discovered source files. Includes a helper function to check if a path is within a parent directory and handles missing tqdm dependency gracefully.</small></li>
<li style="margin-bottom: 1em;"><a href="setup.html">setup</a><br/><small>This module defines a setup configuration for packaging Python modules. It specifies three modules to be included in the distribution: &quot;explaincode&quot;, &quot;parser_cpp&quot;, and &quot;parser_java&quot;. The setup function from setuptools is called with these modules listed in the py_modules parameter, indicating they should be installed as part of the package. The configuration is structured to execute only when the script is run directly as the main module.</small></li>
<li style="margin-bottom: 1em;"><a href="summarize_utils.html">summarize_utils</a><br/><small>Module implements a chunked text summarization function using an LLM client and response caching. It handles large texts by splitting them into chunks when needed, summarizes each chunk, and then merges the partial summaries into a final summary. The implementation includes token budgeting to manage context window limits, fallback behaviors for failures during chunking or summarization, and recursive merging of summaries when the initial merge exceeds token limits. The function supports customizable system prompts and prompt types, with caching to avoid redundant processing of identical inputs.</small></li>
<li style="margin-bottom: 1em;"><a href="test_cache.html">test_cache</a><br/><small>Module defines tests for a ResponseCache class that handles caching of file summaries and progress tracking. Tests verify cache persistence through file I/O, retrieval of cached entries, handling of missing keys, and management of progress data including setting, retrieving, and clearing progress entries. The cache uses JSON file storage with key-based lookup for summaries and separate progress tracking functionality.</small></li>
<li style="margin-bottom: 1em;"><a href="test_chunk_utils.html">test_chunk_utils</a><br/><small>The module defines a set of tests for text tokenization and chunking functionality. It verifies that a tokenizer correctly encodes and decodes text, removing specific formatting tokens during decoding. It also tests the chunking utility to ensure it reconstructs content accurately, splits markdown headings properly, and preserves code block formatting across chunks. The tests use a consistent tokenizer obtained from a utility function and validate both tokenization behavior and chunking logic.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator.html">test_docgenerator</a><br/><small>Module defines test cases for a documentation generator tool. Tests cover handling of invalid Python files, generation of class and function summaries, skipping non-UTF8 files, sanitization of project summaries, use of README content, cleaning output directories, chunked text summarization, prompt overhead handling during chunking, recursive merging of long texts, atomic function chunking, splitting large classes by methods, subclass method processing, and support for C++ and Java file types. Tests utilize mocking of LLMClient and related functions to isolate functionality and verify correct behavior under various conditions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a><br/><small>Test function that verifies documentation generation for nested class methods. Creates a temporary project structure with a nested class containing a method, then runs the docgenerator main function to produce HTML documentation. The test checks that the generated HTML contains expected summary text for both the nested class and its method, confirming proper documentation extraction and formatting. Uses mocking to simulate LLM client behavior without external dependencies.</small></li>
<li style="margin-bottom: 1em;"><a href="test_explaincode.html">test_explaincode</a><br/><small>This module defines a comprehensive test suite for a documentation generation tool, covering functionality across multiple document formats including markdown, HTML, DOCX, and Python files. The tests validate text extraction while preserving formatting, heading preservation in DOCX documents, HTML rendering with table of contents and sources, manual summary creation with LLM integration, PDF output generation, and graceful handling of missing dependencies. Key test areas include document collection with filtering, evidence mapping with priority and limits, placeholder detection, manual parsing with inferred sections, reference validation, section inference logic, snippet extraction with size limits, and code scanning that skips non-source directories. The test suite employs mocked LLM clients, temporary file structures, and various file formats while utilizing fixtures for creating test data and mocking external dependencies. Additional tests focus on code documentation generation functionality including snippet categorization, file ranking with language-specific patterns, LLM placeholder filling with logging, code scanning behavior with different flags, manual generation with fallback mechanisms, and output file handling such as index insertion. The suite also verifies automatic chunking and summarization logic in manual documentation generation, confirming multiple LLM calls during chunking, proper system prompts for chunk and merge operations, logging of chunking steps, application of post-processing hooks, parallel execution of chunk summaries, hierarchical merging with</small></li>
<li style="margin-bottom: 1em;"><a href="test_html_writer.html">test_html_writer</a><br/><small>Module defines tests for HTML documentation generation functions. Tests cover index page creation with nested module structures, module page rendering including classes, functions, variables, and their documentation, subfunction and subclass handling, and syntax highlighting for C++ and Java code snippets. Each test validates specific HTML output elements and formatting.</small></li>
<li style="margin-bottom: 1em;"><a href="test_integration.html">test_integration</a><br/><small>Module defines tests for the `docgenerator` tool, verifying HTML generation from code files in multiple languages including Python, MATLAB, C++, and Java. Tests check creation of HTML files with summaries inserted, and confirm static assets are copied correctly regardless of current working directory. The tests mock an LLM client to simulate documentation generation without external dependencies.</small></li>
<li style="margin-bottom: 1em;"><a href="test_llm_client.html">test_llm_client</a><br/><small>Module defines tests for an LLM client including ping functionality, summary generation with retry logic, and prompt template usage. Tests cover success and failure scenarios for pinging, handling HTTP errors during summarization, and filtering output text. It verifies correct behavior when using different prompt templates based on input type and ensures proper sanitization of summary text. The tests utilize mocking to isolate the client&#x27;s behavior from external dependencies.</small></li>
<li style="margin-bottom: 1em;"><a href="test_manual_utils.html">test_manual_utils</a><br/><small>Module defines tests for documentation utilities. Includes functions to count tokens in text and verify chunking behavior respects token limits. Tests validate placeholder identification in text strings.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_cpp.html">test_parser_cpp</a><br/><small>Test function that validates parsing of C++ source code into structured data. Reads a sample C++ file containing namespace, function, class, and member definitions with documentation comments. Verifies extraction of module docstring, namespace name, function details including name, docstring, and source code, and class structure with variables and methods. Checks that all parsed elements match expected values from the test input.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_java.html">test_parser_java</a><br/><small>Test function that verifies parsing of a Java source file. Creates a temporary Java file with package, class, field, and method documentation, then validates the parsed output contains expected docstrings, names, types, and source code snippets for each element. Uses the parse_java_file function from parser_java module to perform the parsing.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_matlab.html">test_parser_matlab</a><br/><small>Module defines tests for parsing MATLAB files. Includes test cases for parsing a simple MATLAB file with one function and header comments, and another test case for parsing a file containing multiple functions. Uses `parse_matlab_file` function to process MATLAB source files and verifies parsed output structure including header text and function metadata such as names and argument lists. Tests utilize temporary files created in a provided test directory path.</small></li>
<li style="margin-bottom: 1em;"><a href="test_parser_python.html">test_parser_python</a><br/><small>Module defines test functions for parsing Python files. Tests cover simple modules with functions and classes, complex function signatures with positional-only and keyword-only parameters, nested class and function structures, deeply nested classes, and inner classes defined within methods. Each test creates a temporary Python file, parses it using `parse_python_file`, and asserts expected structure and content of parsed elements including docstrings, signatures, source code, and nested components. Tests validate extraction of module docstrings, class information with methods, function details including return types, and hierarchical structures of nested definitions.</small></li>
<li style="margin-bottom: 1em;"><a href="test_resume_progress.html">test_resume_progress</a><br/><small>Test function that verifies resume functionality of documentation generation with caching. Sets up a project with two Python modules and mocks various docgenerator functions to simulate processing. Configures a mock cache that raises an exception on the first progress update to simulate a failure. Executes main generation process which fails, then resumes it. Verifies that only the second module is processed after resuming, and that both HTML files are generated. Confirms cache progress tracking behavior and ensures all modules are eventually documented.</small></li>
<li style="margin-bottom: 1em;"><a href="test_retrofit_sidebar.html">test_retrofit_sidebar</a><br/><small>Module defines tests for `retrofit_sidebar` function and its command-line interface. Tests validate sidebar generation from Python source files, checking link creation for modules and submodules. Includes test cases for missing source or documentation directories, verifying error handling and exit codes. Uses `BeautifulSoup` for HTML parsing and manipulation.</small></li>
<li style="margin-bottom: 1em;"><a href="test_reviewer.html">test_reviewer</a><br/><small>Module defines tests for detecting specific phrases and issues in documentation. Tests check for assistant phrasing, contradictions, and hallucinations in module summaries and method definitions. Includes functionality to automatically remove assistant phrasing when using an autofix option. Tests use a temporary file path and capture console output to verify detection messages. The module generates HTML documentation pages and runs a main review function on them.</small></li>
<li style="margin-bottom: 1em;"><a href="test_sanitize_docs.html">test_sanitize_docs</a><br/><small>Tests for the sanitize_docs utility that verify removal of AI disclaimers from HTML files in a directory. The tests check that text content within HTML elements is preserved while AI-related disclaimer text is removed. The first test validates removal of disclaimers from paragraph elements, and the second test validates removal from heading and list items while preserving their structural formatting.</small></li>
<li style="margin-bottom: 1em;"><a href="test_scanner.html">test_scanner</a><br/><small>The module defines pytest functions to test the `scan_directory` function from the `scanner` module. It includes tests for ignoring specific directories, handling mixed file types, skipping `.git` folders, and supporting C++, C++, and Java file extensions. The tests use a helper function `create_files` to set up temporary file structures in a test directory. Each test validates the output of `scan_directory` against expected file paths, ensuring correct filtering and inclusion of files based on specified criteria.</small></li>
</ul>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
