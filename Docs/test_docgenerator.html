<!-- Generated by DocGen-LM -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>test_docgenerator</title>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <button id="sidebar-toggle">Menu</button>
    <div class="sidebar">
        <h2>Navigation</h2>
        <ul>
        <li><a href="index.html"><strong>üè† Project Overview</strong></a></li>
<li><a href="cache.html">cache</a></li>
<li><a href="chunk_utils.html">chunk_utils</a></li>
<li><a href="docgenerator.html">docgenerator</a></li>
<li><a href="explaincode.html">explaincode</a></li>
<li><a href="gui_wrapper.html">gui_wrapper</a></li>
<li><a href="html_writer.html">html_writer</a></li>
<li><a href="llm_client.html">llm_client</a></li>
<li><a href="manual_utils.html">manual_utils</a></li>
<li><a href="parser_matlab.html">parser_matlab</a></li>
<li><a href="parser_python.html">parser_python</a></li>
<li><a href="reviewer.html">reviewer</a></li>
<li><a href="scanner.html">scanner</a></li>
<li><a href="setup.html">setup</a></li>
<li><a href="summarize_utils.html">summarize_utils</a></li>
<li><a href="test_cache.html">test_cache</a></li>
<li><a href="test_chunk_utils.html">test_chunk_utils</a></li>
<li><a href="test_docgenerator.html">test_docgenerator</a></li>
<li><a href="test_docgenerator_subclasses.html">test_docgenerator_subclasses</a></li>
<li><a href="test_explaincode.html">test_explaincode</a></li>
<li><a href="test_html_writer.html">test_html_writer</a></li>
<li><a href="test_integration.html">test_integration</a></li>
<li><a href="test_llm_client.html">test_llm_client</a></li>
<li><a href="test_manual_utils.html">test_manual_utils</a></li>
<li><a href="test_parser_matlab.html">test_parser_matlab</a></li>
<li><a href="test_parser_python.html">test_parser_python</a></li>
<li><a href="test_reviewer.html">test_reviewer</a></li>
<li><a href="test_scanner.html">test_scanner</a></li>
        </ul>
    </div>
    <div class="content">
        <h1>test_docgenerator</h1>
        <p>The module contains unit tests for a code documentation generator. It uses the `unittest.mock` library to patch dependencies and the `pathlib` library for file operations. The tests cover various scenarios such as skipping invalid Python files, generating summaries for classes and functions, handling non-UTF8 files, and ensuring project summaries are sanitized. Additionally, it includes tests for summarizing text in chunks, merging summaries recursively, and structuring chunkers to keep functions atomic or split large classes by methods.</p>
<h2>Functions</h2>
<h3 id="test_skips_invalid_python_file">test_skips_invalid_python_file(tmp_path: Path) -&gt; None</h3>
<p>This function `test_skips_invalid_python_file` tests the behavior of the `main` function from the `docgenerator.py` module when encountering an invalid Python file. It sets up a temporary project directory with an invalid Python file (`bad.py`) that contains syntax errors due to leading zeros in numeric literals. The function then calls the `main` function with this project directory and specifies an output directory for the documentation.

The test uses a mock object for the `LLMClient` class to simulate interactions with a language model, ensuring that it responds as expected without actually making network requests. The `ping` method is mocked to return `True`, indicating that the client is available, and the `summarize` method is also mocked to return a dummy summary string.

After calling the `main` function, the test asserts that the return value is `0`, indicating successful execution. It then checks that only an index page (`index.html`) is generated in the output directory, while no documentation file for the invalid Python file (`bad.html`) is created. This confirms that the system correctly skips files with syntax errors during documentation generation.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_skips_invalid_python_file</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    <span style="color: #3D7B7B; font-style: italic"># file with invalid syntax due to leading zero</span>
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;bad.py&quot;</span>)<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;x = 08</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>)

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;summary&quot;</span>
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    <span style="color: #3D7B7B; font-style: italic"># only index page should be generated</span>
    <span style="color: #008000; font-weight: bold">assert</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;index.html&quot;</span>)<span style="color: #666666">.</span>exists()
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #AA22FF; font-weight: bold">not</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;bad.html&quot;</span>)<span style="color: #666666">.</span>exists()
</code></pre>
<h3 id="test_generates_class_and_function_summaries">test_generates_class_and_function_summaries(tmp_path: Path) -&gt; None</h3>
<p>The function `test_generates_class_and_function_summaries` tests the generation of class and function summaries using a mock LLM client. It creates a temporary project directory with a Python module containing a class and a function, then calls the main function to generate documentation. The mock client returns predefined summaries for different elements, and the test asserts that the generated HTML files contain the expected summaries.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_generates_class_and_function_summaries</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.py&quot;</span>)<span style="color: #666666">.</span>write_text(
        <span style="color: #BA2121">&#39;class Foo:</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    &quot;&quot;&quot;Doc&quot;&quot;&quot;</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    pass</span><span style="color: #AA5D1F; font-weight: bold">\n\n</span><span style="color: #BA2121">&#39;</span> <span style="color: #BA2121">&quot;def bar():</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    return 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
    )

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>side_effect <span style="color: #666666">=</span> [
            <span style="color: #BA2121">&quot;module summary&quot;</span>,
            <span style="color: #BA2121">&quot;project summary&quot;</span>,
            <span style="color: #BA2121">&quot;class summary&quot;</span>,
            <span style="color: #BA2121">&quot;improved class doc&quot;</span>,
            <span style="color: #BA2121">&quot;function summary&quot;</span>,
            <span style="color: #BA2121">&quot;improved function doc&quot;</span>,
        ]
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    html <span style="color: #666666">=</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.html&quot;</span>)<span style="color: #666666">.</span>read_text(encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;improved class doc&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;function summary&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
    index_html <span style="color: #666666">=</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;index.html&quot;</span>)<span style="color: #666666">.</span>read_text(encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;module summary&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> index_html
</code></pre>
<h3 id="test_skips_non_utf8_file">test_skips_non_utf8_file(tmp_path: Path) -&gt; None</h3>
<p>The function `test_skips_non_utf8_file` is a unit test for the `main` function in the `docgenerator.py` module. It verifies that non-UTF-8 encoded files are skipped during documentation generation.

Here&#x27;s what the function does:

1. Creates a temporary project directory with a non-UTF-8 file named `bad.py`.
2. Sets up a mock LLM client using the `patch` decorator to simulate successful pinging and summarization.
3. Calls the `main` function with the project directory and output directory as arguments.
4. Asserts that the return value of `main` is 0, indicating success.
5. Verifies that an index HTML file exists in the output directory.
6. Ensures that a non-UTF-8 encoded file (`bad.py`) does not have a corresponding HTML file in the output directory.

This test ensures that the `main` function correctly handles and skips files with encoding issues during documentation generation.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_skips_non_utf8_file</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;bad.py&quot;</span>)<span style="color: #666666">.</span>write_bytes(<span style="color: #BA2121">b&quot;</span><span style="color: #AA5D1F; font-weight: bold">\xff\xfe\xfd</span><span style="color: #BA2121">&quot;</span>)

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;summary&quot;</span>
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    <span style="color: #008000; font-weight: bold">assert</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;index.html&quot;</span>)<span style="color: #666666">.</span>exists()
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #AA22FF; font-weight: bold">not</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;bad.html&quot;</span>)<span style="color: #666666">.</span>exists()
</code></pre>
<h3 id="test_handles_class_without_docstring">test_handles_class_without_docstring(tmp_path: Path) -&gt; None</h3>
<p>The function `test_handles_class_without_docstring` tests the handling of a Python class without a docstring by creating a temporary project directory, writing a Python file with an unannotated class, and then running the main documentation generation process. It uses a mock LLM client to simulate responses for module, project, and class summaries. The test asserts that the class summary is included in the generated HTML output.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_handles_class_without_docstring</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.py&quot;</span>)<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;class Foo:</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    pass</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>)

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>side_effect <span style="color: #666666">=</span> [
            <span style="color: #BA2121">&quot;module summary&quot;</span>,
            <span style="color: #BA2121">&quot;project summary&quot;</span>,
            <span style="color: #BA2121">&quot;class summary&quot;</span>,
        ]
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    html <span style="color: #666666">=</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.html&quot;</span>)<span style="color: #666666">.</span>read_text(encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;class summary&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
</code></pre>
<h3 id="test_project_summary_is_sanitized">test_project_summary_is_sanitized(tmp_path: Path) -&gt; None</h3>
<p>This function `test_project_summary_is_sanitized` tests the generation of a project summary using the `docgenerator` module. It creates a temporary project directory with a Python file containing a simple function. The function then calls the main entry point of the `docgenerator` module, passing the path to the project and an output directory for the generated documentation.

The test uses a mock client for the language model (`LLMClient`) to simulate responses during the summarization process. It asserts that the return value of the main function is 0, indicating success. The function also checks that the generated HTML file does not contain certain strings (&quot;You can run this&quot; and &quot;It prints.&quot;) and verifies that the project summary was requested by checking the calls made to the mock client&#x27;s `summarize` method.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_project_summary_is_sanitized</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.py&quot;</span>)<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;def foo():</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    pass</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>)

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>side_effect <span style="color: #666666">=</span> [
            <span style="color: #BA2121">&quot;module summary&quot;</span>,
            <span style="color: #BA2121">&quot;project summary&quot;</span>,
            <span style="color: #BA2121">&quot;function summary&quot;</span>,
            <span style="color: #BA2121">&quot;improved function doc&quot;</span>,
        ]
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    html <span style="color: #666666">=</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;index.html&quot;</span>)<span style="color: #666666">.</span>read_text(encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;You can run this&quot;</span> <span style="color: #AA22FF; font-weight: bold">not</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;It prints.&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">any</span>(call<span style="color: #666666">.</span>args[<span style="color: #666666">1</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;project&quot;</span> <span style="color: #008000; font-weight: bold">for</span> call <span style="color: #AA22FF; font-weight: bold">in</span> instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>call_args_list)
</code></pre>
<h3 id="test_readme_summary_used">test_readme_summary_used(tmp_path: Path) -&gt; None</h3>
<p>This function tests the generation of a README summary using the `docgenerator` module. It creates a temporary project directory with a Python file and a README.md file, then calls the `main` function to generate documentation. The test uses a mock LLM client to simulate the summarization process, ensuring that the README is correctly summarized and included in the output HTML.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_readme_summary_used</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.py&quot;</span>)<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;def foo():</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    pass</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>)
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;README.md&quot;</span>)<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;Project docs&quot;</span>)

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>side_effect <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">lambda</span> text, pt, <span style="color: #666666">**</span>kwargs: <span style="color: #BA2121">f&quot;</span><span style="color: #A45A77; font-weight: bold">{</span>pt<span style="color: #A45A77; font-weight: bold">}</span><span style="color: #BA2121"> summary&quot;</span>
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    html <span style="color: #666666">=</span> (output_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;index.html&quot;</span>)<span style="color: #666666">.</span>read_text(encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #BA2121">&quot;readme summary&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> html
    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">any</span>(call<span style="color: #666666">.</span>args[<span style="color: #666666">1</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;readme&quot;</span> <span style="color: #008000; font-weight: bold">for</span> call <span style="color: #AA22FF; font-weight: bold">in</span> instance<span style="color: #666666">.</span>summarize<span style="color: #666666">.</span>call_args_list)
</code></pre>
<h3 id="test_clean_output_dir">test_clean_output_dir(tmp_path: Path) -&gt; None</h3>
<p>The function `test_clean_output_dir` tests the `clean_output_dir` function from the `docgenerator` module. It creates a temporary directory, simulates files and directories within it, and then calls `clean_output_dir` to clean up the output directory. The test asserts that only the custom HTML file remains after cleaning, while other generated files are removed.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_clean_output_dir</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    out <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>
    out<span style="color: #666666">.</span>mkdir()
    generated <span style="color: #666666">=</span> out <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;old.html&quot;</span>
    generated<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;&lt;!-- Generated by DocGen-LM --&gt;</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&lt;html&gt;&lt;/html&gt;&quot;</span>, encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    custom <span style="color: #666666">=</span> out <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;custom.html&quot;</span>
    custom<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;&lt;html&gt;&lt;/html&gt;&quot;</span>, encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)
    asset <span style="color: #666666">=</span> out <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;style.css&quot;</span>
    asset<span style="color: #666666">.</span>write_text(<span style="color: #BA2121">&quot;body </span><span style="color: #A45A77; font-weight: bold">{}</span><span style="color: #BA2121">&quot;</span>, encoding<span style="color: #666666">=</span><span style="color: #BA2121">&quot;utf-8&quot;</span>)

    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">docgenerator</span> <span style="color: #008000; font-weight: bold">import</span> clean_output_dir

    clean_output_dir(<span style="color: #008000">str</span>(out))

    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #AA22FF; font-weight: bold">not</span> generated<span style="color: #666666">.</span>exists()
    <span style="color: #008000; font-weight: bold">assert</span> custom<span style="color: #666666">.</span>exists()
    <span style="color: #008000; font-weight: bold">assert</span> asset<span style="color: #666666">.</span>exists()
</code></pre>
<h3 id="test_summarize_chunked_splits_long_text">test_summarize_chunked_splits_long_text(tmp_path: Path) -&gt; None</h3>
<p>This function tests the `summarize_chunked` function from the `summarize_utils` module. It sets up a tokenizer, creates a cache object, and mocks the `_summarize` function to return &quot;summary&quot;. The function is then called with various parameters, including a client object, cache, key prefix, text, prompt type, maximum context tokens, and chunk token budget. The test asserts that the `_summarize` function was called more than once during the execution of `summarize_chunked`.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_summarize_chunked_splits_long_text</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">summarize_utils</span> <span style="color: #008000; font-weight: bold">import</span> summarize_chunked

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    text <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;word &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">50</span>
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;summarize_utils._summarize&quot;</span>, return_value<span style="color: #666666">=</span><span style="color: #BA2121">&quot;summary&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        summarize_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            text<span style="color: #666666">=</span>text,
            prompt_type<span style="color: #666666">=</span><span style="color: #BA2121">&quot;module&quot;</span>,
            max_context_tokens<span style="color: #666666">=10</span>,
            chunk_token_budget<span style="color: #666666">=5</span>,
        )
        <span style="color: #008000; font-weight: bold">assert</span> mock_sum<span style="color: #666666">.</span>call_count <span style="color: #666666">&gt;</span> <span style="color: #666666">1</span>
</code></pre>
<h3 id="test_chunking_accounts_for_prompt_overhead">test_chunking_accounts_for_prompt_overhead(tmp_path: Path) -&gt; None</h3>
<p>This function tests the `summarize_chunked` function from the `summarize_utils` module. It sets up a tokenizer, cache, and prompt template, calculates the overhead for the system prompt and template, and then calls `summarize_chunked` with a mock summarization client. The test asserts that the mock summarization function was called more than once, indicating that the text was chunked and summarized accordingly.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_chunking_accounts_for_prompt_overhead</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">summarize_utils</span> <span style="color: #008000; font-weight: bold">import</span> summarize_chunked
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">llm_client</span> <span style="color: #008000; font-weight: bold">import</span> SYSTEM_PROMPT, PROMPT_TEMPLATES

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    text <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;word &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">15</span>
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))
    template <span style="color: #666666">=</span> PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>]
    overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>)))
    max_context_tokens <span style="color: #666666">=</span> overhead <span style="color: #666666">+</span> <span style="color: #666666">10</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;summarize_utils._summarize&quot;</span>, return_value<span style="color: #666666">=</span><span style="color: #BA2121">&quot;summary&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        summarize_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            text<span style="color: #666666">=</span>text,
            prompt_type<span style="color: #666666">=</span><span style="color: #BA2121">&quot;module&quot;</span>,
            max_context_tokens<span style="color: #666666">=</span>max_context_tokens,
            chunk_token_budget<span style="color: #666666">=100</span>,
        )
        <span style="color: #008000; font-weight: bold">assert</span> mock_sum<span style="color: #666666">.</span>call_count <span style="color: #666666">&gt;</span> <span style="color: #666666">1</span>
</code></pre>
<h3 id="test_merge_recurses_when_prompt_too_long">test_merge_recurses_when_prompt_too_long(tmp_path: Path) -&gt; None</h3>
<p>This function tests the merging of recursive calls when a prompt is too long. It uses a fake summary function to simulate responses from an LLM client, ensuring that the text does not exceed the maximum context tokens allowed. The test checks if the `summarize_chunked` function correctly merges multiple calls when necessary.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_merge_recurses_when_prompt_too_long</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">summarize_utils</span> <span style="color: #008000; font-weight: bold">import</span> summarize_chunked
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">llm_client</span> <span style="color: #008000; font-weight: bold">import</span> SYSTEM_PROMPT, PROMPT_TEMPLATES

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    text <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;word &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">200</span>
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))
    template <span style="color: #666666">=</span> PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>]
    overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(
        tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>))
    )
    max_context_tokens <span style="color: #666666">=</span> overhead <span style="color: #666666">+</span> <span style="color: #666666">50</span>

    <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fake_sum</span>(client, cache_obj, key, text_arg, prompt_type, <span style="color: #666666">*</span>, system_prompt<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>):
        template <span style="color: #666666">=</span> PROMPT_TEMPLATES<span style="color: #666666">.</span>get(prompt_type, PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>])
        overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(
            tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>))
        )
        available <span style="color: #666666">=</span> max_context_tokens <span style="color: #666666">-</span> overhead
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(text_arg)) <span style="color: #666666">&lt;=</span> available
        <span style="color: #008000; font-weight: bold">if</span> prompt_type <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>:
            <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;summary &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">30</span>
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;short&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;summarize_utils._summarize&quot;</span>, side_effect<span style="color: #666666">=</span>fake_sum) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        summarize_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            text<span style="color: #666666">=</span>text,
            prompt_type<span style="color: #666666">=</span><span style="color: #BA2121">&quot;module&quot;</span>,
            max_context_tokens<span style="color: #666666">=</span>max_context_tokens,
            chunk_token_budget<span style="color: #666666">=10</span>,
        )
        merge_calls <span style="color: #666666">=</span> [c <span style="color: #008000; font-weight: bold">for</span> c <span style="color: #AA22FF; font-weight: bold">in</span> mock_sum<span style="color: #666666">.</span>call_args_list <span style="color: #008000; font-weight: bold">if</span> c<span style="color: #666666">.</span>args[<span style="color: #666666">4</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;docstring&quot;</span>]
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(merge_calls) <span style="color: #666666">&gt;</span> <span style="color: #666666">1</span>
</code></pre>
<details>
<summary>Subfunction: fake_sum(client, cache_obj, key, text_arg, prompt_type, *, system_prompt=&#x27;&#x27;)</summary>
<h4 id="fake_sum">fake_sum(client, cache_obj, key, text_arg, prompt_type, *, system_prompt=&#x27;&#x27;)</h4>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fake_sum</span>(client, cache_obj, key, text_arg, prompt_type, <span style="color: #666666">*</span>, system_prompt<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>):
        template <span style="color: #666666">=</span> PROMPT_TEMPLATES<span style="color: #666666">.</span>get(prompt_type, PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>])
        overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(
            tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>))
        )
        available <span style="color: #666666">=</span> max_context_tokens <span style="color: #666666">-</span> overhead
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(text_arg)) <span style="color: #666666">&lt;=</span> available
        <span style="color: #008000; font-weight: bold">if</span> prompt_type <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>:
            <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;summary &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">30</span>
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;short&quot;</span>
</code></pre>
</details>
<h3 id="test_single_long_partial_is_recursively_chunked">test_single_long_partial_is_recursively_chunked(tmp_path: Path) -&gt; None</h3>
<p>This function tests the recursive chunking of a long text into manageable parts using a language model. It sets up a mock summarization function to simulate responses from the language model and verifies that the text is correctly split into chunks. The test uses a temporary path for caching responses and checks if the number of calls made to the mock summarization function for docstrings exceeds one, ensuring that the text is being chunked appropriately.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_single_long_partial_is_recursively_chunked</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">summarize_utils</span> <span style="color: #008000; font-weight: bold">import</span> summarize_chunked
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">llm_client</span> <span style="color: #008000; font-weight: bold">import</span> SYSTEM_PROMPT, PROMPT_TEMPLATES

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    text <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;word &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">200</span>
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))
    template <span style="color: #666666">=</span> PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>]
    overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>)))
    max_context_tokens <span style="color: #666666">=</span> overhead <span style="color: #666666">+</span> <span style="color: #666666">50</span>

    <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fake_sum</span>(client, cache_obj, key, text_arg, prompt_type, <span style="color: #666666">*</span>, system_prompt<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>):
        template <span style="color: #666666">=</span> PROMPT_TEMPLATES<span style="color: #666666">.</span>get(prompt_type, PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>])
        overhead_local <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(
            tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>))
        )
        available <span style="color: #666666">=</span> max_context_tokens <span style="color: #666666">-</span> overhead_local
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(text_arg)) <span style="color: #666666">&lt;=</span> available
        <span style="color: #008000; font-weight: bold">if</span> prompt_type <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>:
            <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;long &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">200</span>
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;short&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;summarize_utils._summarize&quot;</span>, side_effect<span style="color: #666666">=</span>fake_sum) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        summarize_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            text<span style="color: #666666">=</span>text,
            prompt_type<span style="color: #666666">=</span><span style="color: #BA2121">&quot;module&quot;</span>,
            max_context_tokens<span style="color: #666666">=</span>max_context_tokens,
            chunk_token_budget<span style="color: #666666">=10</span>,
        )
        doc_calls <span style="color: #666666">=</span> [c <span style="color: #008000; font-weight: bold">for</span> c <span style="color: #AA22FF; font-weight: bold">in</span> mock_sum<span style="color: #666666">.</span>call_args_list <span style="color: #008000; font-weight: bold">if</span> c<span style="color: #666666">.</span>args[<span style="color: #666666">4</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;docstring&quot;</span>]
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(doc_calls) <span style="color: #666666">&gt;</span> <span style="color: #666666">1</span>
</code></pre>
<details>
<summary>Subfunction: fake_sum(client, cache_obj, key, text_arg, prompt_type, *, system_prompt=&#x27;&#x27;)</summary>
<h4 id="fake_sum">fake_sum(client, cache_obj, key, text_arg, prompt_type, *, system_prompt=&#x27;&#x27;)</h4>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">fake_sum</span>(client, cache_obj, key, text_arg, prompt_type, <span style="color: #666666">*</span>, system_prompt<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>):
        template <span style="color: #666666">=</span> PROMPT_TEMPLATES<span style="color: #666666">.</span>get(prompt_type, PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>])
        overhead_local <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(
            tokenizer<span style="color: #666666">.</span>encode(template<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>))
        )
        available <span style="color: #666666">=</span> max_context_tokens <span style="color: #666666">-</span> overhead_local
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(text_arg)) <span style="color: #666666">&lt;=</span> available
        <span style="color: #008000; font-weight: bold">if</span> prompt_type <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>:
            <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;long &quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">200</span>
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #BA2121">&quot;short&quot;</span>
</code></pre>
</details>
<h3 id="test_structured_chunker_keeps_functions_atomic">test_structured_chunker_keeps_functions_atomic(tmp_path: Path) -&gt; None</h3>
<p>This function tests the `chunk_utils` module&#x27;s ability to keep functions atomic when chunking text. It creates a Python file with two functions, each containing multiple lines of code. The test uses a mock object for the language model client and a response cache. It then calls the `_summarize_module_chunked` function from the `docgenerator` module, passing in the parsed Python file and other necessary parameters. The function is expected to chunk the text into two parts, each containing one of the functions. The test asserts that the number of chunks is equal to the number of functions and that the source code of the functions is correctly preserved in the chunks.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_structured_chunker_keeps_functions_atomic</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">parser_python</span> <span style="color: #008000; font-weight: bold">import</span> parse_python_file
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">docgenerator</span> <span style="color: #008000; font-weight: bold">import</span> _summarize_module_chunked
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">llm_client</span> <span style="color: #008000; font-weight: bold">import</span> SYSTEM_PROMPT, PROMPT_TEMPLATES

    src <span style="color: #666666">=</span> (
        <span style="color: #BA2121">&quot;def f1():</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #BA2121">&quot;    x = 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;    x += 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">5</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;    return x</span><span style="color: #AA5D1F; font-weight: bold">\n\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #BA2121">&quot;def f2():</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #BA2121">&quot;    y = 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;    y += 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">5</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;    return y</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
    )
    file <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;m.py&quot;</span>
    file<span style="color: #666666">.</span>write_text(src)
    parsed <span style="color: #666666">=</span> parse_python_file(<span style="color: #008000">str</span>(file))

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator._summarize&quot;</span>, return_value<span style="color: #666666">=</span><span style="color: #BA2121">&quot;sum&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        flen <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(parsed[<span style="color: #BA2121">&quot;functions&quot;</span>][<span style="color: #666666">0</span>][<span style="color: #BA2121">&quot;source&quot;</span>]))
        budget <span style="color: #666666">=</span> flen <span style="color: #666666">+</span> <span style="color: #666666">5</span>
        overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>]<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>)))
        _summarize_module_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            module_text<span style="color: #666666">=</span>src,
            module<span style="color: #666666">=</span>parsed,
            tokenizer<span style="color: #666666">=</span>tokenizer,
            max_context_tokens<span style="color: #666666">=</span>overhead <span style="color: #666666">+</span> budget,
            chunk_token_budget<span style="color: #666666">=</span>budget,
        )

        chunks <span style="color: #666666">=</span> [c<span style="color: #666666">.</span>args[<span style="color: #666666">3</span>] <span style="color: #008000; font-weight: bold">for</span> c <span style="color: #AA22FF; font-weight: bold">in</span> mock_sum<span style="color: #666666">.</span>call_args_list <span style="color: #008000; font-weight: bold">if</span> c<span style="color: #666666">.</span>args[<span style="color: #666666">4</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>]
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(chunks) <span style="color: #666666">==</span> <span style="color: #666666">2</span>
        func_sources <span style="color: #666666">=</span> {f[<span style="color: #BA2121">&quot;source&quot;</span>] <span style="color: #008000; font-weight: bold">for</span> f <span style="color: #AA22FF; font-weight: bold">in</span> parsed[<span style="color: #BA2121">&quot;functions&quot;</span>]}
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">set</span>(chunks) <span style="color: #666666">==</span> func_sources
</code></pre>
<h3 id="test_structured_chunker_splits_large_class_by_method">test_structured_chunker_splits_large_class_by_method(tmp_path: Path) -&gt; None</h3>
<p>This function tests the `chunk_utils` module&#x27;s ability to split a large Python class into smaller chunks based on its methods. It uses a mock language model client and a response cache to simulate the summarization process. The test ensures that each method&#x27;s source code is chunked separately and passed to the summarization function.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_structured_chunker_splits_large_class_by_method</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">cache</span> <span style="color: #008000; font-weight: bold">import</span> ResponseCache
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">parser_python</span> <span style="color: #008000; font-weight: bold">import</span> parse_python_file
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">chunk_utils</span> <span style="color: #008000; font-weight: bold">import</span> get_tokenizer
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">docgenerator</span> <span style="color: #008000; font-weight: bold">import</span> _summarize_module_chunked
    <span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">llm_client</span> <span style="color: #008000; font-weight: bold">import</span> SYSTEM_PROMPT, PROMPT_TEMPLATES

    class_src <span style="color: #666666">=</span> (
        <span style="color: #BA2121">&quot;class Foo:</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #BA2121">&quot;    def a(self):</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        x = 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        x += 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">5</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        return x</span><span style="color: #AA5D1F; font-weight: bold">\n\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #BA2121">&quot;    def b(self):</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        y = 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        y += 1</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">*</span> <span style="color: #666666">5</span>
        <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;        return y</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
    )
    file <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;m.py&quot;</span>
    file<span style="color: #666666">.</span>write_text(class_src)
    parsed <span style="color: #666666">=</span> parse_python_file(<span style="color: #008000">str</span>(file))

    tokenizer <span style="color: #666666">=</span> get_tokenizer()
    cache <span style="color: #666666">=</span> ResponseCache(<span style="color: #008000">str</span>(tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;cache.json&quot;</span>))

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator._summarize&quot;</span>, return_value<span style="color: #666666">=</span><span style="color: #BA2121">&quot;sum&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        mlen <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(parsed[<span style="color: #BA2121">&quot;classes&quot;</span>][<span style="color: #666666">0</span>][<span style="color: #BA2121">&quot;methods&quot;</span>][<span style="color: #666666">0</span>][<span style="color: #BA2121">&quot;source&quot;</span>]))
        budget <span style="color: #666666">=</span> mlen <span style="color: #666666">+</span> <span style="color: #666666">5</span>
        overhead <span style="color: #666666">=</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(SYSTEM_PROMPT)) <span style="color: #666666">+</span> <span style="color: #008000">len</span>(tokenizer<span style="color: #666666">.</span>encode(PROMPT_TEMPLATES[<span style="color: #BA2121">&quot;module&quot;</span>]<span style="color: #666666">.</span>format(text<span style="color: #666666">=</span><span style="color: #BA2121">&quot;&quot;</span>)))
        _summarize_module_chunked(
            client<span style="color: #666666">=</span><span style="color: #008000">object</span>(),
            cache<span style="color: #666666">=</span>cache,
            key_prefix<span style="color: #666666">=</span><span style="color: #BA2121">&quot;k&quot;</span>,
            module_text<span style="color: #666666">=</span>class_src,
            module<span style="color: #666666">=</span>parsed,
            tokenizer<span style="color: #666666">=</span>tokenizer,
            max_context_tokens<span style="color: #666666">=</span>overhead <span style="color: #666666">+</span> budget,
            chunk_token_budget<span style="color: #666666">=</span>budget,
        )

        chunks <span style="color: #666666">=</span> [c<span style="color: #666666">.</span>args[<span style="color: #666666">3</span>] <span style="color: #008000; font-weight: bold">for</span> c <span style="color: #AA22FF; font-weight: bold">in</span> mock_sum<span style="color: #666666">.</span>call_args_list <span style="color: #008000; font-weight: bold">if</span> c<span style="color: #666666">.</span>args[<span style="color: #666666">4</span>] <span style="color: #666666">==</span> <span style="color: #BA2121">&quot;module&quot;</span>]
        methods <span style="color: #666666">=</span> parsed[<span style="color: #BA2121">&quot;classes&quot;</span>][<span style="color: #666666">0</span>][<span style="color: #BA2121">&quot;methods&quot;</span>]
        method_sources <span style="color: #666666">=</span> {m[<span style="color: #BA2121">&quot;source&quot;</span>] <span style="color: #008000; font-weight: bold">for</span> m <span style="color: #AA22FF; font-weight: bold">in</span> methods}
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(chunks) <span style="color: #666666">==</span> <span style="color: #008000">len</span>(methods)
        <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">set</span>(chunks) <span style="color: #666666">==</span> method_sources
</code></pre>
<h3 id="test_subclass_methods_are_summarized">test_subclass_methods_are_summarized(tmp_path: Path) -&gt; None</h3>
<p>This function, `test_subclass_methods_are_summarized`, tests the functionality of summarizing methods within subclasses using a mock LLM client. It creates a temporary project directory with a Python file containing a subclass method and sets up an output directory for documentation. The function uses patches to mock the LLM client and the summary generation process, ensuring that the subclass method is included in the summaries. It asserts that the method name &quot;B:m&quot; is called during the summary generation process.</p>
<pre><code><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_subclass_methods_are_summarized</span>(tmp_path: Path) <span style="color: #666666">-&gt;</span> <span style="color: #008000; font-weight: bold">None</span>:
    project_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;proj&quot;</span>
    project_dir<span style="color: #666666">.</span>mkdir()
    (project_dir <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;mod.py&quot;</span>)<span style="color: #666666">.</span>write_text(
        <span style="color: #BA2121">&quot;class A:</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">    class B:</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">        def m(self):</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">            pass</span><span style="color: #AA5D1F; font-weight: bold">\n</span><span style="color: #BA2121">&quot;</span>
    )

    output_dir <span style="color: #666666">=</span> tmp_path <span style="color: #666666">/</span> <span style="color: #BA2121">&quot;docs&quot;</span>

    <span style="color: #008000; font-weight: bold">with</span> patch(<span style="color: #BA2121">&quot;docgenerator.LLMClient&quot;</span>) <span style="color: #008000; font-weight: bold">as</span> MockClient, patch(
        <span style="color: #BA2121">&quot;docgenerator._summarize&quot;</span>,
        return_value<span style="color: #666666">=</span><span style="color: #BA2121">&quot;summary&quot;</span>,
    ) <span style="color: #008000; font-weight: bold">as</span> mock_sum:
        instance <span style="color: #666666">=</span> MockClient<span style="color: #666666">.</span>return_value
        instance<span style="color: #666666">.</span>ping<span style="color: #666666">.</span>return_value <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
        ret <span style="color: #666666">=</span> main([<span style="color: #008000">str</span>(project_dir), <span style="color: #BA2121">&quot;--output&quot;</span>, <span style="color: #008000">str</span>(output_dir)])
        <span style="color: #008000; font-weight: bold">assert</span> ret <span style="color: #666666">==</span> <span style="color: #666666">0</span>

    <span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">any</span>(<span style="color: #BA2121">&quot;B:m&quot;</span> <span style="color: #AA22FF; font-weight: bold">in</span> call<span style="color: #666666">.</span>args[<span style="color: #666666">2</span>] <span style="color: #008000; font-weight: bold">for</span> call <span style="color: #AA22FF; font-weight: bold">in</span> mock_sum<span style="color: #666666">.</span>call_args_list)
</code></pre>
    </div>
    <script src="static/toggle.js"></script>
</body>
</html>
